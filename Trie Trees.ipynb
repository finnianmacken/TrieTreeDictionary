{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "97a735c3b12090ea2224684d94b3072f",
     "grade": true,
     "grade_id": "cell-e7e779c9812636b7",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "NAME = \"Finn Macken\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f3f7defeea63d511",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-14e3f4bcbe37fc5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# CS110 Assignment 3 - Trie trees\n",
    "\n",
    "**Fell free to add more cells to the ones always provided in each question to expand your answers, as needed. Make sure to refer to the [CS110 course guide](https://drive.google.com/file/d/15qthc1zdBTcb7I0BhYjy0O0p186KwmG3/view?pli=1) on the grading guidelines, namely how many HC identifications and applications you are expected to include in each assignment.**\n",
    "\n",
    "If you have any questions, do not hesitate to reach out to the TAs in the Slack channel \"#cs110-algo\", or come to one of your instructors' OHs.\n",
    "\n",
    "### Submission Materials\n",
    "Your assignment submission needs to include the following resources:\n",
    "1. A PDF file must be the first resource and it will be created from the Jupyter notebook template provided in these instructions. Please make sure to use the same function names as the ones provided in the template. If your name is “Dumbledore”, your PDF should be named “Dumbledore.pdf”.\n",
    "2. Your second resource must be a single Python/Jupyter Notebook named “Dumbledore.ipynb”. You can also submit a zip file that includes your Jupyter notebook, but please make sure to name it “Dumbledore.zip” (if your name is Dumbledore!).\n",
    "\n",
    "For details on how to create a nice PDF from a Jupyter notebook, refer again to the [CS110 course guide](https://drive.google.com/file/d/15qthc1zdBTcb7I0BhYjy0O0p186KwmG3/view?pli=1).\n",
    "\n",
    "### HCs and LOs for this assignment\n",
    "[#responsibility], [#PythonProgramming], [#CodeReadability], [#DataStructures], [#ComplexityAnalysis], [#ComputationalCritique]\n",
    "\n",
    "## Question 0\n",
    "\n",
    "Take a screenshot of your CS110 dashboard on Forum where the following is visible:\n",
    "* your name.\n",
    "* your absences for the course have been set to excused up to the end of week 10 (inclusively).\n",
    "\n",
    "This will be evidence that you have submitted acceptable pre-class and make-up work\n",
    "for a CS110 session you may have missed. Check the specific CS110 make-up and\n",
    "pre-class policies in the syllabus of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "081559d2b4772addbed7a79527ad25ec",
     "grade": true,
     "grade_id": "cell-5798297773c8b032",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Notes: for some reason, loading the picture was causing a LaTeX error, which in turn was causing the PDF conversion to fail. Instead, I uploaded it to a publicly accessible Google Drive, which is available here: https://drive.google.com/file/d/1f0LYDEy6hkwieTe8uqqDlwH8hw0K_aDs/view?usp=sharing\n",
    "\n",
    "Hope this is sufficient!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Auto-completion functionalities are now ubiquitous in search engines, document editors, and messaging apps. How would you go about developing an algorithmic strategy from scratch to implement these computational solutions? In this assignment, you will learn about a new data structure and use it to build a very simple auto-complete engine. Each question in the assignment guides you closer to that objective while encouraging you to contrast this novel data structure to the other ones we have discussed in class.\n",
    "\n",
    "A [trie tree](https://en.wikipedia.org/wiki/Trie), or a prefix tree, is a common data structure that stores a set of strings in a collection of nodes so that all strings with a common prefix are found in the same branch of the tree. Each node is associated with a letter, and as you traverse down the tree, you pick up more letters, eventually forming a word. Complete words are commonly found on the leaf nodes. However, some inner nodes can also mark full words.\n",
    "\n",
    "Let’s use an example diagram to illustrate several important features of tries:\n",
    "\n",
    "- Nodes that mark valid words are marked in yellow. Notice that while all leaves are considered valid words, only some inner nodes contain valid words, while some remain only prefixes to valid words appearing down the branch.\n",
    "\n",
    "- The tree does not have to be balanced, and the height of different branches depends on its contents.\n",
    "\n",
    "- In our implementation, branches never merge to show common suffixes (for example, both ANT and ART end in T, but these nodes are kept separate in their respective branches). However, this is a common first line of memory optimization for tries.\n",
    "\n",
    "- The first node contains an empty string; it “holds the tree together.”\n",
    "\n",
    "Your task in this assignment will be to implement a functional trie tree. You will be able to insert words into a dictionary, lookup valid and invalid words, print your dictionary in alphabetical order, and suggest appropriate suffixes like an auto-complete bot.\n",
    "\n",
    "The assignment questions will guide you through these tasks one by one. To stay safe from breaking your own code, and to reinforce the idea of code versioning, under each new question first **copy your previous (working) code**, and only then **implement the new feature**. The code skeletons provided throughout will make this easier for you at the cost of repeating some large portions of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-819415e8038f6a91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q1: Implement a trie tree\n",
    "\n",
    "In this question, you will write Python code that can take a set/list/tuple of strings and insert them into a trie tree and lookup whether a specific word/string is present in the trie tree.\n",
    "\n",
    "### Q1a: Theoretical pondering\n",
    "\n",
    "Two main approaches to building trees, you might recall from class, are making separate Tree and Node classes, or only making a Node class. Which method do you think is a better fit for trie trees, and why? **Justify your reasoning in around 100 words.** You will use your chosen approach throughout the assignment, so don't rush this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "811497ae51dcbf9f2c96eae22b05dcc1",
     "grade": true,
     "grade_id": "cell-4e464655d6bebd29",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "One of the fundamental purposes of classes is to encapsulate all of the data (attributes) and operations (methods)  associated with a specific functionality (in Python, modelled as an object). With trie trees, it's clear that we have two distinct sets of functionalities (i.e. objects). First, we have the functionality of a Node: the attributes that describe their values and and relationships, and the methods that govern their operations and representation (e.g. ``__repr__``, ``__gt__``). \n",
    "\n",
    "Second, we have the functionality of a Tree, which has operations and attributes that are extremely distinct from both a Node and any of the basic Python data structures: tree-based lookup, insert and pre-order traversal methods, a ``root`` node, and so on. There are two other options: encoding these within the Node class itself, or using another data structure (e.g. list or dictionary) to store Nodes. \n",
    "\n",
    "The former breaks the single responsibility principle (SRP): nodes now have methods that execute both on themselves, and on collections of themselves. This is needlessly convoluted and much harder to code, visualise and debug. \n",
    "\n",
    "The latter relies on data structures that are not built to represent a trie tree. For example, no native data structure represents the concept of a ``root`` node well, and iteraters and trees have fundamentally different traversal methods. This leads to a disjunct between the operations that you want to implement and those that the data structures natively support, making programming more difficult and less intuitive. Finally, you can't override magic methods for default object types. This makes processes such as initialisation with a wordbank much harder and less integrated.\n",
    "\n",
    "In conclusion, the combination of a Tree and Node makes the most sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4cf53874138c22a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1b: Practical implementation\n",
    "\n",
    "In the two cells below, there are two code skeletons. Depending on your answer to Q1a, either **implement a Node and a Trie class** or **implement a Node class**. Choose the corresponding code cell and delete the other one.\n",
    "\n",
    "For your class(es), write **insert()** and **lookup()** methods, which will insert a word into the trie tree and look it up, respectively. Use the code skeleton and examine the specifications of its docstrings to guide you on the details of inputs and outputs to each method.\n",
    "\n",
    "If you are coding two classes, your Trie should, upon initiation, create the root Node. If you are coding a single class, use an attribute to mark the root node.\n",
    "\n",
    "Finally, make sure that the trie can be **initiated with a wordbank as an input**. This means that a user can create a trie and feed it an initial dictionary of words at the same time (like in the tests below), which will be automatically inserted into the trie upon its creation. Likely, this will mean that your \\_\\_init\\_\\_() has to make some calls to your insert() method.\n",
    "\n",
    "Several test cases have been provided for your convenience and these include some, but not all, possible edge cases. If the implementation is correct, your code will pass all the tests. In addition, create at least **three more tests** to demonstrate that your code is working correctly and justify why such test cases are appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "11c3f8d85989c48d7be0ab556853d071",
     "grade": true,
     "grade_id": "cell-4584c49085ca66fe",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# VERSION 1 - Node + Trie classes\n",
    "\n",
    "class Node:\n",
    "    \"\"\"This class represents one node of a trie tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: string\n",
    "        The letter associated with each node\n",
    "    children: lst of Nodes\n",
    "        All of the letters that follow from the current Node for words in the tree\n",
    "    word_end: Boolean\n",
    "        boolean that indicates if the current node is the end of a word in the tree\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.children = [] # list of Node objects\n",
    "        self.word_end = False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Data: \\\"{self.data}\\\", Word End: {self.word_end}\"\n",
    "        \n",
    "class Trie:\n",
    "    \"\"\"This class represents the entirety of a trie tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    The parameters for Trie's __init__ are not predetermined.\n",
    "    However, you will likely need one or more of them.    \n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    insert(self, word)\n",
    "        Inserts a word into the trie, creating nodes as required.\n",
    "    lookup(self, word)\n",
    "        Determines whether a given word is present in the trie.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, word_list = None):\n",
    "        \"\"\"Creates the Trie instance, inserts initial words if provided.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        word_list : list or string\n",
    "            List of strings or string to be inserted into the trie upon creation.\n",
    "        \"\"\"\n",
    "        self.root = Node('')\n",
    "\n",
    "        if word_list:\n",
    "            self._insert_wordbank(word_list)\n",
    "            \n",
    "    def _process_wordbank(self, word_bank):\n",
    "        \"\"\"\n",
    "        Preprocesses the word bank potentially provided at initialisation by removing illegal characters,\n",
    "        spacing characters, etc. \n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        word_bank : list or string\n",
    "            List of strings or string to be inserted into the trie upon creation.\n",
    "            \n",
    "        Output\n",
    "        -----\n",
    "        processed_word_bank:\n",
    "            list of processed words to be inserted\n",
    "        \"\"\"\n",
    "        if type(word_bank) == str:\n",
    "            bad_chars = [';', ',', '.', '?', '!', '_', '[', ']', ':', '“', '”', '\"', '–', '-']\n",
    "            just_text = [letter for letter in word_bank if letter not in bad_chars]\n",
    "            without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in just_text)\n",
    "            processed_wordbank = [word for word in without_newlines.split(\" \") if word != \"\"]\n",
    "            return processed_wordbank\n",
    "        elif type(word_bank) == list:\n",
    "            return word_bank  \n",
    "        else:\n",
    "            return list(word_bank)\n",
    "        \n",
    "    \n",
    "    def _insert_wordbank(self, word_bank):\n",
    "        \"\"\"\n",
    "        Inserts each word in the word_bank into the tree by calling the insert method\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        word_list : list or string\n",
    "            List of strings or string to be inserted into the trie upon creation. \n",
    "        \n",
    "        Output\n",
    "        ----------\n",
    "        None\n",
    "        \"\"\"\n",
    "        processed_wordbank = self._process_wordbank(word_bank)\n",
    "        for word in processed_wordbank:\n",
    "            self.insert(word)\n",
    "                \n",
    "        \n",
    "    def insert(self, word):\n",
    "        \"\"\"Inserts a word into the trie, creating missing nodes on the go.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be inserted into the trie.\n",
    "        \n",
    "        Output\n",
    "        -----------\n",
    "        None (inserts the word into the tree)\n",
    "        \"\"\"\n",
    "        root = self.root\n",
    "        processed_word = word.lower()\n",
    "\n",
    "        for letter_index in range(len(processed_word)):\n",
    "            # deals with the case where the letter doesn't exist and must be inserted\n",
    "            if all([child.data != processed_word[letter_index] for child in root.children]): # if there are no nodes associated with the letter along the current path\n",
    "                letter_node = Node(processed_word[letter_index])\n",
    "                root.children.append(letter_node)\n",
    "                \n",
    "                root = letter_node\n",
    "                \n",
    "                # checking if the letter is the last one in the word\n",
    "                if letter_index == len(processed_word) - 1:\n",
    "                    letter_node.word_end = True\n",
    "            \n",
    "            # deals with the case where the letter already exists\n",
    "            else:\n",
    "                for child in root.children:\n",
    "                    if child.data == processed_word[letter_index]:\n",
    "                        if letter_index == len(processed_word) - 1:\n",
    "                            child.word_end = True\n",
    "                        root = child\n",
    "                        break\n",
    "\n",
    "        \n",
    "    def lookup(self, word):\n",
    "        \"\"\"Determines whether a given word is present in the trie.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be looked-up in the trie.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if the word is present in trie; False otherwise.\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        Your trie should ignore whether a word is capitalized.\n",
    "        E.g. trie.insert('Prague') should lead to trie.lookup('prague') = True\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        root = self.root # starts the lookup at the root node\n",
    "        processed_word = word.lower() # converts the string to lower case\n",
    "\n",
    "        if word == \"\":\n",
    "            return False\n",
    "        \n",
    "        for letter_index in range(len(processed_word)):\n",
    "            if all([child.data != processed_word[letter_index] for child in root.children]):\n",
    "                    return False\n",
    "            else:\n",
    "                for child in root.children:\n",
    "                    if child.data == processed_word[letter_index]:\n",
    "                        root = child\n",
    "                        if letter_index == len(processed_word) - 1:\n",
    "                            if not child.word_end:\n",
    "                                  return False\n",
    "                        break # ends the for loop early if it finds a match\n",
    "        return True # only returns true if the for loop has moved through every letter in the word without an error\n",
    "\n",
    "\n",
    "# Here are several tests that have been created for you.\n",
    "# Remeber that the question asks you to provide several more,\n",
    "# as well as to justify them.\n",
    "\n",
    "# This is Namárië, JRRT's elvish poem written in Quenya\n",
    "wordbank = \"Ai! laurië lantar lassi súrinen, yéni unótimë ve rámar aldaron! Yéni ve lintë yuldar avánier mi oromardi lisse-miruvóreva Andúnë pella, Vardo tellumar nu luini yassen tintilar i eleni ómaryo airetári-lírinen. Sí man i yulma nin enquantuva? An sí Tintallë Varda Oiolossëo ve fanyar máryat Elentári ortanë, ar ilyë tier undulávë lumbulë; ar sindanóriello caita mornië i falmalinnar imbë met, ar hísië untúpa Calaciryo míri oialë. Sí vanwa ná, Rómello vanwa, Valimar! Namárië! Nai hiruvalyë Valimar. Nai elyë hiruva. Namárië!\".replace(\"!\", \"\").replace(\"?\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\";\", \"\").split()\n",
    "\n",
    "trie = Trie(wordbank)\n",
    "\n",
    "# be careful about capital letters!\n",
    "assert trie.lookup('oiolossëo') == True\n",
    "# this is a prefix, but also a word in itself\n",
    "assert trie.lookup('an') == True\n",
    "# this is a prefix, but NOT a word\n",
    "assert trie.lookup('ele') == False\n",
    "# not in the wordbank\n",
    "assert trie.lookup('Mithrandir') == False\n",
    "\n",
    "# Note: There are several ways in which we can condense the text cleaning syntax, \n",
    "# without repeating the method replace() multiple times, \n",
    "# but we are leaving it this way for clarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "db8835bdc160cdd17141b8260a2af617",
     "grade": true,
     "grade_id": "cell-4584c49085ca66fe0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Edge Case Tests\n",
    "wordbank = \"The quick brown fox jumps over the lazy dog. He did this 15 times -- 5 times more than a cat. My dog's the best!\"\n",
    "edge_tree = Trie(wordbank)\n",
    "\n",
    "assert edge_tree.lookup(\"\") == False\n",
    "assert edge_tree.lookup(\" \") == False\n",
    "assert edge_tree.lookup(\"--\") == False\n",
    "assert edge_tree.lookup(\"The \") == False\n",
    "assert edge_tree.lookup(\" The\") == False\n",
    "assert edge_tree.lookup(\"THE\") == True\n",
    "assert edge_tree.lookup(\"tHe\") == True\n",
    "assert edge_tree.lookup(\"15\") == True\n",
    "assert edge_tree.lookup(\"1\") == False\n",
    "assert edge_tree.lookup('dog\\'s') == True\n",
    "\n",
    "\n",
    "\n",
    "# Insertion Tests\n",
    "wordbank = \"The quick brown fox jumps over the lazy dog.\"\n",
    "insertion_tree = Trie(wordbank)\n",
    "insertion_tree.insert(\"the\")\n",
    "insertion_tree.insert('them')\n",
    "assert insertion_tree.lookup('them') == True\n",
    "\n",
    "# Localisation Tests\n",
    "\n",
    "english = \"The quick brown fox jumps over the lazy dog\"\n",
    "japanese = \"速い茶色のキツネは怠惰な犬を飛び越えます\"\n",
    "turkish = \"Hızlı kahverengi tilki tembel köpeğin üzerinden atlar\"\n",
    "\n",
    "\n",
    "english_tree = Trie(english)\n",
    "\n",
    "assert english_tree.lookup(\"jumps\") == True\n",
    "assert english_tree.lookup(\"jump\") == False\n",
    "\n",
    "turkish_tree = Trie(turkish)\n",
    "\n",
    "assert turkish_tree.lookup('Hızlı') == True\n",
    "assert turkish_tree.lookup(\"Hizli\") == False\n",
    "assert turkish_tree.lookup(\"köpeğin\") == True\n",
    "assert turkish_tree.lookup(\"kopegin\") == False\n",
    "\n",
    "japanese_tree = Trie(japanese)\n",
    "\n",
    "assert japanese_tree.lookup(\"速い茶色のキツネは怠惰な犬を飛び越えます\") == True\n",
    "assert japanese_tree.lookup(\"速く\") == False\n",
    "japanese_tree.insert(\"速く\")\n",
    "assert japanese_tree.lookup(\"速く\") == True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ac5151742a9020c9ff29adfddd184005",
     "grade": true,
     "grade_id": "cell-5bf2526fdd4f6dbb",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e0219e06970eefa3ca107c30948978cf",
     "grade": true,
     "grade_id": "cell-e100769456a0b431",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## Test Justifications\n",
    "The tests above are appropriate because they deal with a wide variety of edge cases and different inputs that you might not initially consider when implementing a trie tree. We know from the Elvish test case above that most common cases are likely to be covered, and so I chose to focus on some less likely cases.\n",
    "\n",
    "First, I tested many edge cases in English: checking for spaces, empty strings, words with different captialisation patterns, and finally numbers. I designed my lookup function to return False for an empty string, because even though it was in the tree, it didn't make sense to consider as a \"word\". Given that we end up using the tree for autocompletion, this definitely makes sense: you don't want it to treat empty strings as valid autocompletions.\n",
    "\n",
    "What's also interesting is that it preserves words like \"dog's\", which uses a possessive apostrophe. Because of the input format, however, you have to use an escape character (``\\``).\n",
    "\n",
    "I also tested insertions, making sure that the same principles held with for the insertion function.\n",
    "\n",
    "Finally, I tested the tree with localisation examples, using English, Turkish and Japanese. Using English as a control case, Turkish and Japanese were good examples because the formula uses English spacing and grammar, but has foreign letters that don't appear in English, while the latter is extremely different, and doesn't include spacing.\n",
    "\n",
    "I tested the tree on foreign letters, which it passed. For Japanese, the test-case highlighted an intentional shortcoming of the tree: without spaces, it doesn't know what constitutes a word. This means that completely separate rules would have to be created for Japanese, which uses characters to designate word relationships rather than letters and spacing. For words that are added individually, however, it works well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fef57ab83eed68f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2: The computational complexity of tries\n",
    "\n",
    "Evaluate the **computational complexity of the insert() and lookup()** methods in a trie. What are the relevant variables for runtime? You might want to consider how the height of a trie is computed to start addressing this question.  Make sure to clearly explain your reasoning.\n",
    "\n",
    "**Compare your results to** the runtime of the same operations on **a BST**. Can you think of specific circumstances where the practical runtimes of operations supported by tries are higher than for BSTs? Explain your answer. If you believe such circumstances could be common, why would someone even bother implementing a trie tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8ef94b05f7f1ff341e0e2ad7072f3706",
     "grade": true,
     "grade_id": "cell-df9c5720e271a448",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "# Trie Trees\n",
    "## Lookup\n",
    "The lookup operation that I've implemented works in the following way. First, it converts the string to lower case, which takes time proportional to the length of the string (which compared to the number of nodes in the tree can be approximated as a constant value Theta(1)).\n",
    "\n",
    "Then, the algorithm starts at the root. It iterates through all of the children of the root, and returns False if none of them are the given letter. If one of them is the child, it sets it equal to the root and repeats the algorithm. This repeats for each letter of the input word. If it goes through all of these iterations without breaking, and ends up on a node that is designated as the end of the word, then we know it must be in the tree, and it returns True.\n",
    "\n",
    "This implementation means that the time complexity of ``lookup()`` depends entirely on the length of the word, not the length of the tree.\n",
    "\n",
    "The worst case occurs when the given word actually is in the tree -- if it's not, the algorithm will stop prematurely and take less time.\n",
    "\n",
    "Let's designate the length of the word as ``k``. For each letter of index ``1...k``, the algorithm has at most got to loop through all of the children of the associated node twice: once to check that the child exists using ``all``, and another time to find the letter, which at worst is the last in the ``children`` list. There are also some other comparisons which take constant time. We also need to convert the word to lowercase, which takes ``O(k)`` because you need to check every letter of the word.\n",
    "\n",
    "The length of the children lists do not scale as ``k`` does -- we can therefor them as a constant term ``O(1)``, although the coefficient is likely very high, as we can easily imagine children lists having upwards of 10-20 letter nodes in them (but almost certainly not much higher than that).\n",
    "\n",
    "This means the overall time complexity can be modelled as the following:\n",
    "$$T(k)=O(k)+k*(O(1)+O(1)+O(1))$$\n",
    "$$=O(k)+3k*O(1)$$\n",
    "$$=O(k)+3O(k)=4O(k)=O(k)$$\n",
    "\n",
    "Therefore, the time complexity of the lookup operation is ``O(k)``.\n",
    "\n",
    "In the best case, the only thing that improves is the coefficient of the constant time operation. This means the time complexity of the lookup operation is ``Theta(k)``.\n",
    "\n",
    "## Insert\n",
    "The insertion operation is similar to the lookup operation, and their time complexities end up being the same. Starting at the root, the algorithm checks if each letter of the word exists as it moves down the tree. If it does, it makes that node the new active node and continues the process. If not, it creates a new node with the letter value, and continues downwards. When it reaches the end of the word, it sets the ``word_end`` attribute for whatever node it ends at.\n",
    "\n",
    "For a word of length ``k``, the algorithm loops through an entire list of children either once or twice (a constant time operation, as dicused above). If it needs to create the node, it performs several constant time operations (appending, assigning the root, checking if this is the last letter etc.). If the node already exists, it also only performs constant time operations (checking if it's the last letter, etc.)\n",
    "\n",
    "Since in both cases, it only performs constant time operations, we know that the time complexity is ``O(k)`` -- the only non-constant factor is the loop through the letters of the word.\n",
    "\n",
    "In the best case, the letter always already exists (i.e. the word's already in the tree), meaning we can skip a few of the operations (creating Nodes, appending them to the children list, etc.). Even here, the only thing that changes is the coefficients of the constant term. This means the time complexity of the insert operation is ``Theta(k)``.\n",
    "\n",
    "\n",
    "# Binary Search Tree Implementation\n",
    "There are several ways you could implement a word dictionary using a binary search tree. For this analysis, I will explore the approach where each node contains a word, and alphabetic/lexicographic order is used to determine whether a node is in the left or right subtrees of a given node.\n",
    "\n",
    "For example, let's say you have a tree that represents the dictionary: [banana, orange, pear, apple].\n",
    "\n",
    "First, the BST would set the root node equal to \"banana\". Then, it start at the root, and would make \"orange\" the right child of \"banana\" (because o is later in the alphabet than b), and banana doesn't have a right child. Then, it would start at the root again, move to \"orange\", and then set \"pear\" as its right child. Finally, it would start at the root and set \"apple\" as \"banana\"'s left child (because a < b in the alphabet). It would need special logic for dealing with characters such as ö, ê, ł, etc., because they don't have a clear lexicographic relationship. This could be done by deciding an arbitrary hierarchy for each character (e.g. o < ô < ö < ò). Obviously, this isn't an optimal way of dealing with the problem, but that's mostly because BSTs are pretty terrible at implementing dictionaries.\n",
    "\n",
    "## Lookup\n",
    "To look-up a word in a binary search tree, you need to use the BST property to descend the tree, checking each node until you find one with a word that matches the specified input. For a tree of height ``h``, this has time complexity of ``O(h)``, since the word could be in one of the leaf nodes of the tree. If the tree is balanced, this is ``O(log n)``, where ``n`` is the total number of words in the dictionary (because a balanced tree splits in 2 at every node, meaning it has height ``log(n)``). If extremely unbalanced, the tree could approximate a linked list, in which case the time complexity is ``O(n)``.\n",
    "\n",
    "\n",
    "## Insert\n",
    "To insert a word in a binary search tree, you need to follow the BST property until you hit a ``NIL`` node where the word can be inserted, at which point you insert it. This also has time complexity ``O(h)``, because you could have to insert the node after one of the leaves. As discussed above, this is ``O(log n)`` if the tree is approximately balanced, and ``O(n)`` if it's approximately unbalanced.\n",
    "\n",
    "\n",
    "# Comparison\n",
    "## Lookup\n",
    "For a trie tree, lookup takes ``O(k)`` regardless of the tree size, where ``k`` is the length of the word. For an equivalent BST, it takes ``O(n)`` if un-balanced and ``O(log n)`` if balanced, where ``n`` is the number of nodes in the tree.\n",
    "\n",
    "In almost every practical case, the time complexity of lookup in a trie tree dominates that of a BST. This is because the length of a word is almost always significantly smaller than the number of nodes in a tree, meaning the total work required is far longer.\n",
    "\n",
    "\n",
    "## Insert\n",
    "For a trie tree, insertion takes ``O(k)`` regardless of the tree size, where ``k`` is the length of the word. For an equivalent BST, it takes ``O(n)`` if un-balanced and ``O(log n)`` if balanced, where ``n`` is the number of nodes in the tree.\n",
    "\n",
    "Again, trie trees dominate BST trees here, because insertion time complexity is based on word length and ignores the height of the tree, whereas BST insertion depends on the height of the tree. For pretty much any appropriately sized dictionary, the number of nodes will far outstrip the length of any given word.\n",
    "\n",
    "\n",
    "## Exceptions\n",
    "Despite the conclusions of this asymptotic analysis, we can imagine a scenario where BST trees might outperform trie trees. If we had a small word dictionary with words that all had a massive number of individual characters, the constant factors hidden by the asymptotic notation for trie trees might lead to a longer running time, but this is an extreme example that rarely ever happens.\n",
    "\n",
    "In constrast, a word bank that was nearly sorted , will produce an extremely unbalanced tree, creating a worst case scenario. There are many contexts where this might be the case, such as if you're ingesting an existing dictionary of words to trian an autocompletion algorithm.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-39a6cc552b8ddb5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q3: Print a dictionary in alphabetical order.\n",
    "\n",
    "Recall the meaning of pre-order traversal from your previous classes. On the data structure of a trie tree, pre-order traversal corresponds to an alphabetically sorted list of the words contained within (provided that your node children are sorted alphabetically).\n",
    "\n",
    "For example, on the example trie given in the introduction, pre-order traversal would return [\"A\", \"AM, \"AN\", \"ANT\", \"AR, \"ART, \"D\" and \"DO\"]. However, since we are only interested in the actual words, we would not include \"D\" and \"AR\" in our list. To that end, you will need to include an attribute for each node, storing the information about whether its content is a word or not.\n",
    "\n",
    "Copy your existing code to the code skeleton cell below, and add a new method to it, **alphabetical_list()**. This will be version two of your autocomplete script.\n",
    "\n",
    "The method should **return a list**, whose elements will be the words contained in the tree, in alphabetical order. On top of passing the provided test, write at least **three more tests**, and explain why they are appropriate.\n",
    "\n",
    "**Approach choice:** Remember the two possible approaches to the problem, as we’ve seen at the start of the course: iterative or recursive. Depending on your trie implementation, one might be preferred over the other. **Justify your choice of approach** in a few sentences (~100 words).\n",
    "\n",
    "Copy-paste your previous code and make adjustments to this \"new version\", so that you cannot break the old one :).\n",
    "\n",
    "*(Notes: If you choose a recursive approach, it might be useful to implement a helper method that is not called by the user but by preorder_traversal(). Also, watch out for the [unintuitive Python behaviour](https://web.archive.org/web/20200221224620/http://effbot.org/zone/default-values.htm) if defining functions with mutable default parameter values.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f4fe7855a4823fe9f0a15bcf3790d841",
     "grade": true,
     "grade_id": "cell-da1a00263d7d154b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"This class represents one node of a trie tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: string\n",
    "        The letter associated with each node\n",
    "    children: lst of Nodes\n",
    "        All of the letters that follow from the current Node for words in the tree\n",
    "    word_end: Boolean\n",
    "        boolean that indicates if the current node is the end of a word in the tree\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.children = [] # list of Node objects\n",
    "        self.word_end = False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Data: \\\"{self.data}\\\", Word End: {self.word_end}\"\n",
    "        \n",
    "class Trie:\n",
    "    \"\"\"This class represents the entirety of a trie tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    The parameters for Trie's __init__ are not predetermined.\n",
    "    However, you will likely need one or more of them.    \n",
    "    \n",
    "    Public Methods\n",
    "    -------\n",
    "    insert(self, word)\n",
    "        Inserts a word into the trie, creating nodes as required.\n",
    "    lookup(self, word)\n",
    "        Determines whether a given word is present in the trie.\n",
    "    alphabetical_list(self)\n",
    "        Devlivers the content of the tree in alphabetical order\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def _process_wordbank(self, word_bank):\n",
    "        \"\"\"\n",
    "        Preprocesses the word bank potentially provided at initialisation by removing illegal characters,\n",
    "        spacing characters, etc. \n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        word_bank : list or string\n",
    "            List of strings or string to be inserted into the trie upon creation.\n",
    "            \n",
    "        Output\n",
    "        -----\n",
    "        processed_word_bank:\n",
    "            list of processed words to be inserted\n",
    "        \"\"\"\n",
    "        if type(word_bank) == str:\n",
    "            bad_chars = [';', ',', '.', '?', '!', '_', '[', ']', ':', '“', '”', '\"', '–', '-']\n",
    "            just_text = [letter for letter in word_bank if letter not in bad_chars]\n",
    "            without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in just_text)\n",
    "            processed_wordbank = [word for word in without_newlines.split(\" \") if word != \"\"]\n",
    "            return processed_wordbank\n",
    "        elif type(word_bank) == list:\n",
    "            return word_bank  \n",
    "        else:\n",
    "            return list(word_bank)\n",
    "        \n",
    "    \n",
    "    def _insert_wordbank(self, word_bank):\n",
    "        \"\"\"\n",
    "        Inserts each word in the word_bank into the tree by calling the insert method\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        word_list : list or string\n",
    "            List of strings or string to be inserted into the trie upon creation. \n",
    "        \n",
    "        Output\n",
    "        ----------\n",
    "        None\n",
    "        \"\"\"\n",
    "        processed_wordbank = self._process_wordbank(word_bank)\n",
    "        for word in processed_wordbank:\n",
    "            self.insert(word)\n",
    "                \n",
    "    def __init__(self, word_list = None):\n",
    "        \"\"\"Creates the Trie instance, inserts initial words if provided.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word_list : list\n",
    "            List of strings to be inserted into the trie upon creation.\n",
    "        \"\"\"\n",
    "        self.root = Node('')\n",
    "        \n",
    "        if word_list:\n",
    "            self._insert_wordbank(word_list)\n",
    "        \n",
    "    def insert(self, word):\n",
    "        \"\"\"Inserts a word into the trie, creating missing nodes on the go.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be inserted into the trie.\n",
    "        \"\"\"\n",
    "        root = self.root\n",
    "        processed_word = word.lower()\n",
    "\n",
    "        for letter_index in range(len(processed_word)):\n",
    "            # deals with the case where the letter doesn't exist and must be inserted\n",
    "            if all([child.data != processed_word[letter_index] for child in root.children]): # if there are no nodes associated with the letter along the current path\n",
    "                letter_node = Node(processed_word[letter_index])\n",
    "                root.children.append(letter_node)\n",
    "                \n",
    "                root = letter_node\n",
    "                \n",
    "                # checking if the letter is the last one in the word\n",
    "                if letter_index == len(processed_word) - 1:\n",
    "                    letter_node.word_end = True\n",
    "            \n",
    "            # deals with the case where the letter already exists\n",
    "            else:\n",
    "                for child in root.children:\n",
    "                    if child.data == processed_word[letter_index]:\n",
    "                        if letter_index == len(processed_word) - 1:\n",
    "                            child.word_end = True\n",
    "                        root = child\n",
    "                        break\n",
    "\n",
    "        \n",
    "    def lookup(self, word):\n",
    "        \"\"\"Determines whether a given word is present in the trie.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be looked-up in the trie.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if the word is present in trie; False otherwise.\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        Your trie should ignore whether a word is capitalized.\n",
    "        E.g. trie.insert('Prague') should lead to trie.lookup('prague') = True\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        root = self.root # starts the lookup at the root node\n",
    "        processed_word = word.lower() # converts the string to lower case\n",
    "\n",
    "        if word == \"\":\n",
    "            return False\n",
    "        \n",
    "        for letter_index in range(len(processed_word)):\n",
    "            if all([child.data != processed_word[letter_index] for child in root.children]):\n",
    "                    return False\n",
    "            else:\n",
    "                for child in root.children:\n",
    "                    if child.data == processed_word[letter_index]:\n",
    "                        root = child\n",
    "                        if letter_index == len(processed_word) - 1:\n",
    "                            if not child.word_end:\n",
    "                                  return False\n",
    "                        break # ends the for loop early if it finds a match\n",
    "        return True # only returns true if the for loop has moved through every letter in the word without an error\n",
    "\n",
    "    def alphabetical_list(self):\n",
    "        \"\"\"\n",
    "        Delivers the content of the trie in alphabetical order.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            List of strings, all words from the trie in alphabetical order.\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "        root = self.root\n",
    "\n",
    "        word_list = []  \n",
    "\n",
    "        def _alphabetical_list(letter_node, fragment):\n",
    "            \"\"\"\n",
    "            Inner function that executes and isolates the recursive part of alphabetical_list. \n",
    "            Performs tree traversal, keeping track of word fragments and recursively appending\n",
    "            fragments to word_list if they represent full words\n",
    "            \n",
    "            Parameters\n",
    "            -----------\n",
    "            letter_node: Node\n",
    "                Starting node for the recursive function to execute from\n",
    "            fragment: str\n",
    "                string that represents the word fragment associated with the path up to that point\n",
    "            \n",
    "            Output\n",
    "            ---------\n",
    "            None\n",
    "            \"\"\"\n",
    "            fragment += letter_node.data # recursively add nodes to the running variable fragment\n",
    "            \n",
    "            if letter_node.word_end == True:\n",
    "                # Deals with leaf nodes\n",
    "                if letter_node.children == []:\n",
    "                    word_list.append(fragment)\n",
    "                # Deals with word-ends that aren't leaf nodes\n",
    "                else:\n",
    "                    word_list.append(fragment)\n",
    "                    for child in letter_node.children:\n",
    "                        _alphabetical_list(child, fragment)\n",
    "            # Deals with cases where the specified node is not a word_end\n",
    "            else:\n",
    "                for child in letter_node.children:\n",
    "                    _alphabetical_list(child, fragment) # recurse for all children\n",
    "\n",
    "        _alphabetical_list(root, \"\")\n",
    "        return sorted(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "282c05cd9f6d2c6870f28ce5d693c0aa",
     "grade": true,
     "grade_id": "cell-7d2cb3ead49482a1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# intiate the test by uncommenting one of the lines below, depending on your approach\n",
    "\n",
    "wordbank = \"Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Duis pulvinar. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos hymenaeos. Nunc dapibus tortor vel mi dapibus sollicitudin. Etiam quis quam. Curabitur ligula sapien, pulvinar a vestibulum quis, facilisis vel sapien.\".replace(\",\", \"\").replace(\".\", \"\").split()\n",
    "\n",
    "trie = Trie(wordbank)\n",
    "\n",
    "assert trie.alphabetical_list() == ['a','ad','adipiscing','amet','aptent', 'class','consectetuer','conubia', 'curabitur','dapibus','dolor','duis', 'elit','etiam','facilisis','hymenaeos', 'inceptos','ipsum','ligula','litora', 'lorem','mi','nostra','nunc','per', 'pulvinar','quam','quis','sapien', 'sit','sociosqu','sollicitudin','taciti', 'torquent','tortor','vel','vestibulum']\n",
    "\n",
    "# TESTING EDGE CASES\n",
    "\n",
    "edge_case1 = 'hi'\n",
    "edge_case2 = '5 4 3 2 1 apple banana'\n",
    "edge_case3 = 'ę ė ē ë ê é è'\n",
    "edge_case4 = \"\"\n",
    "edge_case5 = \"Hızlı kahverengi tilki tembel köpeğin üzerinden atlar\"\n",
    "edge_case6 = '\"Ai! laurië lantar lassi súrinen, yéni unótimë ve rámar aldaron! Yéni ve lintë yuldar avánier mi oromardi lisse-miruvóreva Andúnë pella, Vardo tellumar nu luini yassen tintilar i eleni ómaryo airetári-lírinen. Sí man i yulma nin enquantuva? An sí Tintallë Varda Oiolossëo ve fanyar máryat Elentári ortanë, ar ilyë tier undulávë lumbulë; ar sindanóriello caita mornië i falmalinnar imbë met, ar hísië untúpa Calaciryo míri oialë. Sí vanwa ná, Rómello vanwa, Valimar! Namárië! Nai hiruvalyë Valimar. Nai elyë hiruva. Namárië!'\n",
    "edge_case1_tree = Trie(edge_case1)\n",
    "edge_case2_tree = Trie(edge_case2)\n",
    "edge_case3_tree = Trie(edge_case3)\n",
    "edge_case4_tree = Trie(edge_case4)\n",
    "edge_case5_tree = Trie(edge_case5)\n",
    "edge_case6_tree = Trie(edge_case6)\n",
    "\n",
    "assert edge_case1_tree.alphabetical_list() == ['hi']\n",
    "assert edge_case2_tree.alphabetical_list() == ['1', '2', '3', '4', '5', 'apple', 'banana']\n",
    "assert edge_case3_tree.alphabetical_list() == ['è', 'é', 'ê', 'ë', 'ē', 'ė', 'ę']\n",
    "assert edge_case4_tree.alphabetical_list() == []\n",
    "assert edge_case5_tree.alphabetical_list() == ['atlar', 'hızlı', 'kahverengi', 'köpeğin', 'tembel', 'tilki', 'üzerinden']\n",
    "assert edge_case6_tree.alphabetical_list() == ['ai',\n",
    " 'airetárilírinen',\n",
    " 'aldaron',\n",
    " 'an',\n",
    " 'andúnë',\n",
    " 'ar',\n",
    " 'avánier',\n",
    " 'caita',\n",
    " 'calaciryo',\n",
    " 'eleni',\n",
    " 'elentári',\n",
    " 'elyë',\n",
    " 'enquantuva',\n",
    " 'falmalinnar',\n",
    " 'fanyar',\n",
    " 'hiruva',\n",
    " 'hiruvalyë',\n",
    " 'hísië',\n",
    " 'i',\n",
    " 'ilyë',\n",
    " 'imbë',\n",
    " 'lantar',\n",
    " 'lassi',\n",
    " 'laurië',\n",
    " 'lintë',\n",
    " 'lissemiruvóreva',\n",
    " 'luini',\n",
    " 'lumbulë',\n",
    " 'man',\n",
    " 'met',\n",
    " 'mi',\n",
    " 'mornië',\n",
    " 'máryat',\n",
    " 'míri',\n",
    " 'nai',\n",
    " 'namárië',\n",
    " 'nin',\n",
    " 'nu',\n",
    " 'ná',\n",
    " 'oialë',\n",
    " 'oiolossëo',\n",
    " 'oromardi',\n",
    " 'ortanë',\n",
    " 'pella',\n",
    " 'rámar',\n",
    " 'rómello',\n",
    " 'sindanóriello',\n",
    " 'sí',\n",
    " 'súrinen',\n",
    " 'tellumar',\n",
    " 'tier',\n",
    " 'tintallë',\n",
    " 'tintilar',\n",
    " 'undulávë',\n",
    " 'untúpa',\n",
    " 'unótimë',\n",
    " 'valimar',\n",
    " 'vanwa',\n",
    " 'varda',\n",
    " 'vardo',\n",
    " 've',\n",
    " 'yassen',\n",
    " 'yuldar',\n",
    " 'yulma',\n",
    " 'yéni',\n",
    " 'ómaryo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "feaef91115374444e8a12307cc0003a0",
     "grade": true,
     "grade_id": "cell-7d2cb3ead49482a10",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3a5dfb505c1964b99baa5e7897813333",
     "grade": true,
     "grade_id": "cell-51cd58cc5c843d84",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "# Test Justifications\n",
    "The Lorem Ipsum test already covers most normal cases for the ``alphabetical_list()`` method, and so when creating supplementary tests, I chose to focus primarly on edge cases. First, I tested a single word to make sure the recursion didn't fail when there weren't multiple calls. Then, I tested combinations of numbers and variables. My algorithm places numbers first in the order (lexicographically), and then sorts between numbers numerically (e.g. 1 < 4 even though 'f' comes before 'o' in the alphabet). This seemed appropriate, as its the way that most databases are ordered.\n",
    "\n",
    "Then, I tested how the algorithm handled diacritic comparison. It does so using the order in which they show up on the keyboard as options, which seemed as appropriate an order as any other. Finally, I tested using two non-english examples. As expected, it performed without issues.\n",
    "\n",
    "These tests were appropriate becauase they supplemented the test that was provided and covered unintuitive edge cases that might appear relatively frequently, such as the use of diacritics or the inclusion of numerical values in strings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative vs. Recursive Approach\n",
    "\n",
    "The ``alphabetical_list()`` function has to be able to find every word that's present in the tree by evaluating the ``word_end`` attribute, many of which will not be leaf nodes (because they themselves are prefixes of longer words). This problem seems more appropriate for a recursive solution, because trees themselves are recursively composed of sub-trees. This means that you can write code which performs the desired operation (pre-order traversal) on the smallest possible sub-tree (a node and its children), and with very little adjustment can have it apply to the tree as a whole. In contrast, iterating through a trie tree doesn't make as much intuitive sense: each node represents a branching pathway to many other nodes, and you don't have a neat iterative collection of nodes (relationships are stored in pointer attributes instead).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49d7083065cc304d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4: Find the k most common words in a speech.\n",
    "\n",
    "To mathematically determine the overall connotation of a speech, you might want to compute which words are most frequently used and then run a [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis). To this end, add a method to your code, **k_most_common()** that will take as an input k, an integer, and return a list of the k most common words from the dictionary within the trie. The structure of the output list should be such that each entry is a tuple, the first element being the word and the second an integer of its frequency (see docstring if you’re confused).\n",
    "\n",
    "To complete this exercise, you don’t have to bother with resolving ties (for example, if k = 1, but there are two most common words with the same frequency, you can return either of them), but consider it an extra challenge and let us know if you believe you managed to solve it.\n",
    "\n",
    "The test cell below downloads and preprocesses several real-world speeches, and then runs the k-most-common word analysis of them; your code should pass the tests. As usual, add at least **three more tests**, and justify why they are relevant to your code (feel free to find more speeches to start analysing too!).\n",
    "\n",
    "Again, copy-paste your previous code and make adjustments to this \"new version\". The first cell has been locked to stop you from accidentally deleting the docstrings.\n",
    "\n",
    "Completing this question well will help you to tackle Q5!\n",
    "\n",
    "*(Hint: This task will probably require your nodes to store more information about the frequency of words inserted into the tree. One data structure that might be very useful to tackle the problem of traversing the tree and finding most common words is heaps — you are allowed to use the heapq library or another alternative for this task.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX HEAP CLASS\n",
    "\n",
    "class MaxHeap:\n",
    "    \"\"\" \n",
    "    A class that implements properties and methods \n",
    "    that support a max priority queue data structure\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    heap : arr \n",
    "        A Python list where key values in the max heap are stored\n",
    "    heap_size: int\n",
    "        An integer counter of the number of keys present in the max heap\n",
    "    \"\"\"  \n",
    "\n",
    "    def __init__(self, heap = []):    \n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \"\"\"    \n",
    "        self.heap = heap\n",
    "        self.heap_size = len(self.heap)\n",
    "        \n",
    "    def left(self, i):\n",
    "        \"\"\"\n",
    "        Takes the index of the parent node\n",
    "        and returns the index of the left child node\n",
    "        \n",
    "        Works with Python indices.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        i: int\n",
    "          Index of parent node\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        int\n",
    "          Index of the left child node\n",
    "\n",
    "        \"\"\"\n",
    "        return 2 * i + 1\n",
    "\n",
    "    def right(self, i):\n",
    "        \"\"\"\n",
    "        Takes the index of the parent node\n",
    "        and returns the index of the right child node.\n",
    "        \n",
    "        Works with Python indices.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        i: int\n",
    "            Index of parent node\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        int\n",
    "            Index of the right child node\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        return 2 * i + 2\n",
    "\n",
    "    def parent(self, i):\n",
    "        \"\"\"\n",
    "        Takes the index of the child node\n",
    "        and returns the index of the parent node\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        i: int\n",
    "            Index of child node\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        int\n",
    "            Index of the parent node\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        return (i - 1)//2\n",
    "\n",
    "    def maxk(self):     \n",
    "        \"\"\"\n",
    "        Returns the highest key in the priority queue. Works because the maximum\n",
    "        value in a max-heap is always at the root node\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        int\n",
    "            the highest key in the priority queue\n",
    "\n",
    "        \"\"\"\n",
    "        return self.heap[0]     \n",
    "    \n",
    "  \n",
    "    def heappush(self, key):  \n",
    "        \"\"\"\n",
    "        Insert a key into a priority queue \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        key: int\n",
    "            The key value to be inserted\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.heap.append(-float(\"inf\"))\n",
    "        self.increase_key(self.heap_size,key)\n",
    "        self.heap_size+=1\n",
    "        \n",
    "    def increase_key(self, i, key): \n",
    "        \"\"\"\n",
    "        Modifies the value of a key in a max priority queue\n",
    "        with a higher value\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        i: int\n",
    "            The index of the key to be modified\n",
    "        key: int\n",
    "            The new key value\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if key < self.heap[i]:\n",
    "            raise ValueError('new key is smaller than the current key')\n",
    "        self.heap[i] = key\n",
    "        while i > 0 and self.heap[self.parent(i)] < self.heap[i]:\n",
    "            j = self.parent(i)\n",
    "            holder = self.heap[j]\n",
    "            self.heap[j] = self.heap[i]\n",
    "            self.heap[i] = holder\n",
    "            i = j     \n",
    "       \n",
    "    def heapify(self, i):\n",
    "        \"\"\"\n",
    "        Creates a max heap from the index given\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        i: int\n",
    "            The index of of the root node of the subtree to be heapify\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        None\n",
    "        \"\"\"\n",
    "        l = self.left(i)\n",
    "        r = self.right(i)\n",
    "        heap = self.heap\n",
    "        if l <= (self.heap_size-1) and heap[l]>heap[i]:\n",
    "            largest = l\n",
    "        else:\n",
    "            largest = i\n",
    "        if r <= (self.heap_size-1) and heap[r] > heap[largest]:\n",
    "            largest = r\n",
    "        if largest != i:\n",
    "            heap[i], heap[largest] = heap[largest], heap[i]\n",
    "            self.heapify(largest)\n",
    "\n",
    "    def heappop(self):\n",
    "        \"\"\"\n",
    "        returns the larest key in the max priority queue\n",
    "        and remove it from the max priority queue\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        int\n",
    "            the max value in the heap that is extracted\n",
    "        \"\"\"\n",
    "        if self.heap_size < 1:\n",
    "            raise ValueError('Heap underflow: There are no keys in the priority queue ')\n",
    "        maxk = self.heap[0]\n",
    "        self.heap[0] = self.heap[-1]\n",
    "        self.heap.pop()\n",
    "        self.heap_size-=1\n",
    "        self.heapify(0)\n",
    "        return maxk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d049686ea2cbf9c211c92914c020929a",
     "grade": true,
     "grade_id": "cell-56d34e4f784db98d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"This class represents one node of a trie tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: string\n",
    "        The letter associated with each node\n",
    "    children: lst of Nodes\n",
    "        All of the letters that follow from the current Node for words in the tree\n",
    "    word_end: Boolean\n",
    "        boolean that indicates if the current node is the end of a word in the tree\n",
    "    parent: Node\n",
    "        Node object that is the parent of the letter\n",
    "    called_count: int\n",
    "        number of times the letter node has been inserted into the tree (only updated for end nodes)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.children = [] # list of Node objects\n",
    "        self.parent = None\n",
    "        self.word_end = False\n",
    "        self.called_count = 0\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Data: \\\"{self.data}\\\", Word End: {self.word_end}\"\n",
    "    \n",
    "    def __gt__(self, other): # custom < operation so that the heap methods work with Nodes\n",
    "        if isinstance(other, Node):\n",
    "            return self.called_count > other.called_count\n",
    "        else:\n",
    "            return self.called_count > other\n",
    "\n",
    "class Trie:\n",
    "    \"\"\"This class represents the entirety of a trie tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    The parameters for Trie's __init__ are not predetermined.\n",
    "    However, you will likely need one or more of them.    \n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    insert(self, word)\n",
    "        Inserts a word into the trie, creating nodes as required.\n",
    "    lookup(self, word)\n",
    "        Determines whether a given word is present in the trie.\n",
    "    alphabetical_list(self)\n",
    "        Delivers the content of the tree in alphabetical order\n",
    "    k_most_common(self, k):\n",
    "        Finds k words inserted into the trie most often\n",
    "    \"\"\"\n",
    "    \n",
    "    def _process_wordbank(self, word_bank):\n",
    "        \"\"\"\n",
    "        Preprocesses the word bank potentially provided at initialisation by removing illegal characters,\n",
    "        spacing characters, etc. \n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        word_bank : list or string\n",
    "            List of strings or string to be inserted into the trie upon creation.\n",
    "            \n",
    "        Output\n",
    "        -----\n",
    "        processed_word_bank:\n",
    "            list of processed words to be inserted\n",
    "        \"\"\"\n",
    "        if type(word_bank) == str:\n",
    "            bad_chars = [';', ',', '.', '?', '!', '_', '[', ']', ':', '“', '”', '\"', '–', '-']\n",
    "            just_text = [letter for letter in word_bank if letter not in bad_chars]\n",
    "            without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in just_text)\n",
    "            processed_wordbank = [word for word in without_newlines.split(\" \") if word != \"\"]\n",
    "            return processed_wordbank\n",
    "        elif type(word_bank) == list:\n",
    "            return word_bank  \n",
    "        else:\n",
    "            return list(word_bank)\n",
    "        \n",
    "    def _insert_wordbank(self, word_bank):\n",
    "        \"\"\"\n",
    "        Inserts each word in the word_bank into the tree by calling the insert method\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        word_list : list or string\n",
    "            List of strings or string to be inserted into the trie upon creation. \n",
    "        \n",
    "        Output\n",
    "        ----------\n",
    "        None\n",
    "        \"\"\"\n",
    "        processed_wordbank = self._process_wordbank(word_bank)\n",
    "        for word in processed_wordbank:\n",
    "            self.insert(word)\n",
    "                \n",
    "    def __init__(self, word_list = None):\n",
    "        \"\"\"Creates the Trie instance, inserts initial words if provided.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word_list : list or string\n",
    "            List of strings or string to be inserted into the trie upon creation.\n",
    "        \"\"\"\n",
    "        self.root = Node('')\n",
    "        \n",
    "        if word_list:\n",
    "            self._insert_wordbank(word_list)\n",
    "        \n",
    "    def insert(self, word):\n",
    "        \"\"\"Inserts a word into the trie, creating missing nodes on the go.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be inserted into the trie.\n",
    "        \"\"\"\n",
    "        root = self.root\n",
    "        processed_word = word.lower()\n",
    "\n",
    "        for letter_index in range(len(processed_word)):\n",
    "            # deals with the case where the letter doesn't exist and must be inserted\n",
    "            if all([child.data != processed_word[letter_index] for child in root.children]): # if there are no nodes associated with the letter along the current path\n",
    "                letter_node = Node(processed_word[letter_index])\n",
    "                letter_node.parent = root # parent attribute used for bottom-up traversal\n",
    "                \n",
    "                root.children.append(letter_node)\n",
    "                root = letter_node\n",
    "                \n",
    "                # checking if the letter is the last one in the word\n",
    "                if letter_index == len(processed_word) - 1:\n",
    "                    letter_node.word_end = True\n",
    "                    letter_node.called_count += 1\n",
    "            \n",
    "            # deals with the case where the letter already exists\n",
    "            else:\n",
    "                for child in root.children:\n",
    "                    if child.data == processed_word[letter_index]:\n",
    "                        if letter_index == len(processed_word) - 1:\n",
    "                            child.called_count += 1\n",
    "                            child.word_end = True\n",
    "                        root = child\n",
    "                        break\n",
    "\n",
    "        \n",
    "    def lookup(self, word):\n",
    "        \"\"\"Determines whether a given word is present in the trie.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be looked-up in the trie.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if the word is present in trie; False otherwise.\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        Your trie should ignore whether a word is capitalized.\n",
    "        E.g. trie.insert('Prague') should lead to trie.lookup('prague') = True\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        root = self.root # starts the lookup at the root node\n",
    "        processed_word = word.lower() # converts the string to lower case\n",
    "\n",
    "        if word == \"\":\n",
    "            return False\n",
    "        \n",
    "        for letter_index in range(len(processed_word)):\n",
    "            if all([child.data != processed_word[letter_index] for child in root.children]):\n",
    "                    return False\n",
    "            else:\n",
    "                for child in root.children:\n",
    "                    if child.data == processed_word[letter_index]:\n",
    "                        root = child\n",
    "                        if letter_index == len(processed_word) - 1:\n",
    "                            if not child.word_end:\n",
    "                                  return False\n",
    "                        break # ends the for loop early if it finds a match\n",
    "        return True # only returns true if the for loop has moved through every letter in the word without an error\n",
    "        \n",
    "    def alphabetical_list(self):\n",
    "        \"\"\"\n",
    "        Delivers the content of the trie in alphabetical order.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            List of strings, all words from the trie in alphabetical order.\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "        root = self.root\n",
    "\n",
    "        word_list = []  \n",
    "\n",
    "        def _alphabetical_list(letter_node, fragment):\n",
    "            \"\"\"\n",
    "            Inner function that executes and isolates the recursive part of alphabetical_list. \n",
    "            Performs tree traversal, keeping track of word fragments and recursively appending\n",
    "            fragments to word_list if they represent full words\n",
    "\n",
    "            Parameters\n",
    "            -----------\n",
    "            letter_node: Node\n",
    "                Starting node for the recursive function to execute from\n",
    "            fragment: str\n",
    "                string that represents the word fragment associated with the path up to that point\n",
    "\n",
    "            Output\n",
    "            ---------\n",
    "            None\n",
    "            \"\"\"\n",
    "            fragment += letter_node.data # recursively add nodes to the running variable fragment\n",
    "\n",
    "            if letter_node.word_end == True:\n",
    "                # Deals with leaf nodes\n",
    "                if letter_node.children == []:\n",
    "                    word_list.append(fragment)\n",
    "                # Deals with word-ends that aren't leaf nodes\n",
    "                else:\n",
    "                    word_list.append(fragment)\n",
    "                    for child in letter_node.children:\n",
    "                        _alphabetical_list(child, fragment)\n",
    "            # Deals with cases where the specified node is not a word_end\n",
    "            else:\n",
    "                for child in letter_node.children:\n",
    "                    _alphabetical_list(child, fragment) # recurse for all children\n",
    "        _alphabetical_list(root, \"\")\n",
    "        return sorted(word_list)\n",
    "\n",
    "    def k_most_common(self, k):\n",
    "        \"\"\"Finds k words inserted into the trie most often.\n",
    "\n",
    "        You will have to tweak some properties of your existing code,\n",
    "        so that it captures information about repeated insertion.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of most common words to be returned.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            List of tuples.\n",
    "            \n",
    "            Each tuple entry consists of the word and its frequency.\n",
    "            The entries are sorted by frequency.\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        >>> print(trie.k_most_common(3))\n",
    "        [(‘the’, 154), (‘a’, 122), (‘i’, 122)]\n",
    "        \n",
    "        I.e. the word ‘the’ has appeared 154 times in the inserted text.\n",
    "        The second and third most common words both appeared 122 times.\n",
    "        \"\"\"\n",
    "        \n",
    "        if k < 1:\n",
    "            return \"Error: k must be greater than or equal to 1\"\n",
    "        end_node_list = []\n",
    "        \n",
    "        root = self.root\n",
    "        def _find_end_nodes(letter_node):\n",
    "            \"\"\"\n",
    "            Inner function that recurses through the tree and finds every node that is an ending\n",
    "            node\n",
    "            \n",
    "            Parameters\n",
    "            -----------\n",
    "            letter_node: Node\n",
    "                Node from which the function starts finding all end nodes\n",
    "            \n",
    "            Output\n",
    "            -----\n",
    "            None\n",
    "            \n",
    "            \"\"\"\n",
    "            if letter_node.word_end == True:\n",
    "                # Deals with the case where the node is a leaf\n",
    "                if letter_node.children == []:\n",
    "                    end_node_list.append(letter_node)\n",
    "                # Deals withe the case where the node is an end_node but not a leaf\n",
    "                else:\n",
    "                    end_node_list.append(letter_node)\n",
    "                    for child in letter_node.children:\n",
    "                        _find_end_nodes(child)\n",
    "            # If not an end_node, recurse for all children of the node\n",
    "            else:\n",
    "                for child in letter_node.children:\n",
    "                    _find_end_nodes(child)\n",
    "        _find_end_nodes(root)\n",
    "        \n",
    "        # Building a MaxHeap to order end nodes by their frequency\n",
    "        max_heap = MaxHeap(end_node_list)\n",
    "        for i in range((max_heap.heap_size//2), -1, -1):\n",
    "            max_heap.heapify(i)\n",
    "            \n",
    "        def word_from_end_node(end_node):\n",
    "            \"\"\"\n",
    "            Constructs a word from a given end node by iterating upwards through the \n",
    "            tree until hitting the root\n",
    "            \n",
    "            Parameters\n",
    "            ---------\n",
    "            end_node: Node\n",
    "                the end_node from which the algorithm constructs the word\n",
    "            \"\"\"\n",
    "            fragment = end_node.data\n",
    "            while end_node.data != \"\": # ends the iteration when it hits the root\n",
    "                end_node = end_node.parent\n",
    "                fragment += end_node.data\n",
    "            return fragment[::-1] # word is reversed because of upwards traversal, so this reverses that\n",
    "        \n",
    "        k_words_list = []\n",
    "        \n",
    "        for i in range(k): # return the number of most common words specified by the user\n",
    "            if max_heap.heap_size > 0: # doesn't return anything if there are no more words left\n",
    "                end_node = max_heap.heappop()\n",
    "                word = word_from_end_node(end_node)\n",
    "                k_words_list.append((word, end_node.called_count))\n",
    "        \n",
    "        k_words_list.sort(key = lambda x:(-x[1], x[0])) # sort first according to count, and second alphabetically\n",
    "        return k_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9ca325123bb216215488cf6770587f2b",
     "grade": true,
     "grade_id": "cell-9e839be729e8377a0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# depending on your choice of approach, \n",
    "# uncomment one of the lines in the for loop to initiate the test\n",
    "\n",
    "# you might have to run 'pip install requests' before running this cell \n",
    "# since you're downloading data from an online resource \n",
    "# please note this might take a while to run\n",
    "\n",
    "# Mehreen Faruqi - Black Lives Matter in Australia: https://bit.ly/CS110-Faruqi\n",
    "# John F. Kennedy - The decision to go to the Moon: https://bit.ly/CS110-Kennedy\n",
    "# Martin Luther King Jr. - I have a dream: https://bit.ly/CS110-King\n",
    "# Greta Thunberg - UN Climate Summit message: https://bit.ly/CS110-Thunberg\n",
    "# Vaclav Havel - Address to US Congress after the fall of Soviet Union: https://bit.ly/CS110-Havel\n",
    "\n",
    "from requests import get\n",
    "speakers = ['Faruqi', 'Kennedy', 'King', 'Thunberg', 'Havel']\n",
    "bad_chars = [';', ',', '.', '?', '!', '_', \n",
    "             '[', ']', ':', '“', '”', '\"', '–', '-']\n",
    "\n",
    "\n",
    "for speaker in speakers:\n",
    "    \n",
    "    # download and clean up the speech from extra characters\n",
    "    speech_full = get(f'https://bit.ly/CS110-{speaker}').text\n",
    "    just_text = ''.join(c for c in speech_full if c not in bad_chars)\n",
    "    without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in just_text)\n",
    "    just_words = [word for word in without_newlines.split(\" \") if word != \"\"]\n",
    "    \n",
    "    trie = Trie(just_words)\n",
    "    \n",
    "    if speaker == 'Faruqi':\n",
    "        Faruqi = [('the', 60), ('and', 45), ('to', 39), ('in', 37), \n",
    "                  ('of', 34), ('is', 25), ('that', 22), ('this', 21), \n",
    "                  ('a', 20), ('people', 20), ('has', 14), ('are', 13), \n",
    "                  ('for', 13), ('we', 13), ('have', 12), ('racism', 12), \n",
    "                  ('black', 11), ('justice', 9), ('lives', 9), ('police', 9)]\n",
    "        assert trie.k_most_common(20) == Faruqi\n",
    "    \n",
    "    elif speaker == 'Kennedy':\n",
    "        Kennedy = [('the', 117), ('and', 109), ('of', 93), ('to', 63), \n",
    "                   ('this', 44), ('in', 43), ('we', 43), ('a', 39), \n",
    "                   ('be', 30), ('for', 27), ('that', 27), ('as', 26), \n",
    "                   ('it', 24), ('will', 24), ('new', 22), ('space', 22), \n",
    "                   ('is', 21), ('all', 15), ('are', 15), ('have', 15), ('our', 15)]\n",
    "        assert trie.k_most_common(21) == Kennedy\n",
    "    \n",
    "    elif speaker == 'Havel':\n",
    "        Havel = [('the', 34), ('of', 23), ('and', 20), ('to', 15), \n",
    "                 ('in', 13), ('a', 12), ('that', 12), ('are', 9), \n",
    "                 ('we', 9), ('have', 8), ('human', 8), ('is', 8), \n",
    "                 ('you', 8), ('as', 7), ('for', 7), ('has', 7), ('this', 7), \n",
    "                 ('be', 6), ('it', 6), ('my', 6), ('our', 6), ('world', 6)]\n",
    "        assert trie.k_most_common(22) == Havel\n",
    "    \n",
    "    elif speaker == 'King':\n",
    "        King = [('the', 103), ('of', 99), ('to', 59), ('and', 54), ('a', 37), \n",
    "                ('be', 33), ('we', 29), ('will', 27), ('that', 24), ('is', 23), \n",
    "                ('in', 22), ('as', 20), ('freedom', 20), ('this', 20), \n",
    "                ('from', 18), ('have', 17), ('our', 17), ('with', 16), \n",
    "                ('i', 15), ('let', 13), ('negro', 13), ('not', 13), ('one', 13)]\n",
    "        assert trie.k_most_common(23) == King\n",
    "    \n",
    "    elif speaker == 'Thunberg':\n",
    "        Thunberg = [('you', 22), ('the', 20), ('and', 16), ('of', 15), \n",
    "                    ('to', 14), ('are', 10), ('is', 9), ('that', 9), \n",
    "                    ('be', 8), ('not', 7), ('with', 7), ('i', 6), \n",
    "                    ('in', 6), ('us', 6), ('a', 5), ('how', 5), ('on', 5), \n",
    "                    ('we', 5), ('all', 4), ('dare', 4), ('here', 4), \n",
    "                    ('my', 4), ('people', 4), ('will', 4)]\n",
    "        assert trie.k_most_common(24) == Thunberg\n",
    "        \n",
    "# Note: There are cleaner and more concise ways to write the code above, \n",
    "# but this way it should be easily understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4ec256edaaab465acf106a23c9df8906",
     "grade": true,
     "grade_id": "cell-9e839be729e8377a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from requests import get\n",
    "\n",
    "edge_case1_tree = Trie([])\n",
    "edge_case2_tree = Trie(['hi', 'hello', 'hello'])\n",
    "assert edge_case1_tree.k_most_common(20) == []\n",
    "assert edge_case2_tree.k_most_common(20) == [('hello', 2), ('hi', 1)]\n",
    "assert edge_case2_tree.k_most_common(-1) == \"Error: k must be greater than or equal to 1\"\n",
    "\n",
    "\n",
    "\n",
    "bad_chars = [';', ',', '.', '?', '!', '_', \n",
    "             '[', ']', ':', '“', '”', '\"', '–', '-']\n",
    "\n",
    "speech_full = get('https://www.gutenberg.org/files/14865/14865.txt').text\n",
    "just_text = ''.join(c for c in speech_full if c not in bad_chars)\n",
    "without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in just_text)\n",
    "just_words = [word for word in without_newlines.split(\" \") if word != \"\"]\n",
    "\n",
    "welsh_tree = Trie(just_words)\n",
    "\n",
    "assert welsh_tree.k_most_common(20) == [('a', 745), ('y', 628), ('yn', 586),\n",
    "                                        ('i', 408), ('ei', 250), ('the', 242),\n",
    "                                        ('ar', 231), ('o', 221), ('of', 166),\n",
    "                                        ('yr', 162), ('ac', 131), ('to', 129), \n",
    "                                        ('fy', 123), ('and', 112), ('eu', 107),\n",
    "                                        ('am', 101), ('dy', 93), ('un', 93),\n",
    "                                        ('oedd', 91), ('na', 90)]\n",
    "\n",
    "speech_full = get('https://www.gutenberg.org/files/59635/59635-0.txt').text\n",
    "just_text = ''.join(c for c in speech_full if c not in bad_chars)\n",
    "without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in just_text)\n",
    "just_words = [word for word in without_newlines.split(\" \") if word != \"\"]\n",
    "\n",
    "norwegian_tree = Trie(just_words)\n",
    "\n",
    "assert norwegian_tree.k_most_common(20) == [('og', 2489), ('i', 2097), ('han', 1556),\n",
    "                                            ('som', 1053), ('det', 1039), ('en', 978),\n",
    "                                            ('av', 976), ('var', 947), ('den', 908),\n",
    "                                            ('at', 850), ('til', 827), ('paa', 751),\n",
    "                                            ('for', 632), ('de', 617), ('er', 604),\n",
    "                                            ('med', 573), ('hans', 474), ('blev', 459),\n",
    "                                            ('et', 400), ('om', 396)]\n",
    "\n",
    "speech_full = get('https://www.gutenberg.org/cache/epub/39561/pg39561.html').text\n",
    "just_text = ''.join(c for c in speech_full if c not in bad_chars)\n",
    "without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in just_text)\n",
    "just_words = [word for word in without_newlines.split(\" \") if word != \"\"]\n",
    "\n",
    "telugu_tree = Trie(just_words)\n",
    "\n",
    "assert telugu_tree.k_most_common(20) == [('<p', 1957), ('ఆ', 241), ('the', 175),\n",
    "                                  ('రామారావు', 124), ('of', 122), ('కాని', 119),\n",
    "                                  ('ఈ', 115), ('తన', 94), ('style=margintop', 87),\n",
    "                                  ('project', 85), ('to', 81), ('మీద', 80),\n",
    "                                  ('or', 77), ('and', 73), ('you', 68), ('ఆమె', 68),\n",
    "                                  ('మాట', 67), ('మీ', 65), ('అని', 64), ('లేదు', 64)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a334b3b36802f203a5b32f9ca4a504c8",
     "grade": true,
     "grade_id": "cell-e89770cfba54e3db",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "# Test Justifications \n",
    "First, I tested several edge cases, such as when the total number of words is smaller than the k value, when the tree is empty and when k < 1. The first two are appropriate because they cover scenarios that might easily occur (e.g. loading in a dataset of unknown size and requesting a large number of most common entries). The third is appropriate because it accounts for the actions of an antagonistic user, ensuring that my error catching systems are working well.\n",
    "\n",
    "Then, I tested the algorithm with texts not in English, sourced from the Gutenberg Project. The first two used an English alphabet (Welsh and Norwegian), and the third used a non-English script (Telugu). The tests indicated that the system was roughly language-agnostic, but I ran into significant issues parsing non-english characters in .txt files. To get Telugu to work, I had to use the HTML file, which accounts for the ``<p>`` terms, etc. This is a shortcoming of the project that I could fix in future iterations: applying additional processing to non-english characters so that they're recognised by the tree.\n",
    "\n",
    "Note: I also tested the tree with other non-standard character systems (Chinese, Ancient Greek, Hebrew). The structure worked, but the characters weren't represented properly because Python couldn't handle the Chinese characters. Fixing this is outside the scope of this assignment -- I'd need a better parser for Chinese, etc. characters.\n",
    "\n",
    "These latter tests were appropriate because they investigated how generalisable the algorithm was to other languages, indicating existing constraints and situation where it works well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6b0e8698889d44bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q5: Implement an autocomplete with a Shakespearean dictionary!\n",
    "\n",
    "Your task is to create a new **autocomplete()** method for your class, which will take a string as an input, and return another string as an output. If the string is not present in the tree, the output will be the same as the input. However, if the string is present in the tree, your task is to find the most common word to which it is a prefix and return that word instead (this can still turn out to be itself).\n",
    "\n",
    "To make the task more interesting, use the test cell code to download and parse “The Complete Works of William Shakespeare”, and insert them into a trie. Your autocomplete should then pass the following tests. As usual, add at least **three more test cases**, and explain why they are appropriate (you can use input other than Shakespeare for them).\n",
    "\n",
    "Make sure to include a minimum **100 word-summary critically evaluating** your autocomplete engine. How does it really work? Your critical reflection needs to specifically evaluate the role of the different data structures used by their algorithm and what is the overall complexity that the algorithm offers. Can we do better? If so, how and by how much?\n",
    "\n",
    "*(Hint: Again, depending on how you choose to implement it, your autocomplete() might make calls to other helper methods. However, make sure that autocomplete() is the method exposed to the user in order to pass the tests.)*\n",
    "\n",
    "*This is a thoroughly frequentist approach to the problem, which is not the only method, and in many cases not the ideal method. However, if you were tasked with implementing something like [this](https://jqueryui.com/autocomplete/) or [this](https://xdsoft.net/jqplugins/autocomplete/), it might just be enough, so let’s give it a go. Good luck!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "523e1a8a65616ad453c28d8804c10a08",
     "grade": true,
     "grade_id": "cell-b43f928d7c5a7b51",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"This class represents one node of a trie tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: string\n",
    "        The letter associated with each node\n",
    "    children: lst of Nodes\n",
    "        All of the letters that follow from the current Node for words in the tree\n",
    "    word_end: Boolean\n",
    "        boolean that indicates if the current node is the end of a word in the tree\n",
    "    parent: Node\n",
    "        Node object that is the parent of the letter\n",
    "    called_count: int\n",
    "        number of times the letter node has been inserted into the tree (only updated for end nodes)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.children = [] # list of Node objects\n",
    "        self.parent = None\n",
    "        self.word_end = False\n",
    "        self.called_count = 0\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Data: \\\"{self.data}\\\", Word End: {self.word_end}\"\n",
    "    \n",
    "    def __gt__(self, other): # custom < operation so that the heap methods work with Nodes\n",
    "        if isinstance(other, Node):\n",
    "            return self.called_count > other.called_count\n",
    "        else:\n",
    "            return self.called_count > other\n",
    "\n",
    "class Trie:\n",
    "    \"\"\"This class represents the entirety of a trie tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    The parameters for Trie's __init__ are not predetermined.\n",
    "    However, you will likely need one or more of them.    \n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    insert(self, word)\n",
    "        Inserts a word into the trie, creating nodes as required.\n",
    "    lookup(self, word)\n",
    "        Determines whether a given word is present in the trie.\n",
    "    alphabetical_list(self)\n",
    "        Delivers the content of the tree in alphabetical order\n",
    "    k_most_common(self, k)\n",
    "        Finds k words inserted into the trie most often\n",
    "    autocomplete(self, prefix)\n",
    "       Finds the most common word with the given prefix. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, word_list = None):\n",
    "        \"\"\"Creates the Trie instance, inserts initial words if provided.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word_list : list\n",
    "            List of strings to be inserted into the trie upon creation.\n",
    "        \"\"\"\n",
    "        self.root = Node('')\n",
    "        \n",
    "        if word_list:\n",
    "            self._insert_wordbank(word_list)\n",
    "    \n",
    "    def _process_wordbank(self, word_bank):\n",
    "        \"\"\"\n",
    "        Preprocesses the word bank potentially provided at initialisation by removing illegal characters,\n",
    "        spacing characters, etc. \n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        word_bank : list or string\n",
    "            List of strings or string to be inserted into the trie upon creation.\n",
    "            \n",
    "        Output\n",
    "        -----\n",
    "        processed_word_bank:\n",
    "            list of processed words to be inserted\n",
    "        \"\"\"\n",
    "        if type(word_bank) == str:\n",
    "            bad_chars = [';', ',', '.', '?', '!', '_', '[', ']', ':', '“', '”', '\"', '–', '-']\n",
    "            just_text = [letter for letter in word_bank if letter not in bad_chars]\n",
    "            without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in just_text)\n",
    "            processed_wordbank = [word for word in without_newlines.split(\" \") if word != \"\"]\n",
    "            return processed_wordbank\n",
    "        elif type(word_bank) == list:\n",
    "            return word_bank  \n",
    "        else:\n",
    "            return list(word_bank)\n",
    "        \n",
    "    def _insert_wordbank(self, word_bank):\n",
    "        \"\"\"\n",
    "        Inserts each word in the word_bank into the tree by calling the insert method\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        word_list : list or string\n",
    "            List of strings or string to be inserted into the trie upon creation. \n",
    "        \n",
    "        Output\n",
    "        ----------\n",
    "        None\n",
    "        \"\"\"\n",
    "        processed_wordbank = self._process_wordbank(word_bank)\n",
    "        for word in processed_wordbank:\n",
    "            self.insert(word)\n",
    "\n",
    "        \n",
    "    def insert(self, word):\n",
    "        \"\"\"Inserts a word into the trie, creating missing nodes on the go.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be inserted into the trie.\n",
    "        \"\"\"\n",
    "        root = self.root\n",
    "        processed_word = word.lower()\n",
    "\n",
    "        for letter_index in range(len(processed_word)):\n",
    "            # deals with the case where the letter doesn't exist and must be inserted\n",
    "            if all([child.data != processed_word[letter_index] for child in root.children]): # if there are no nodes associated with the letter along the current path\n",
    "                letter_node = Node(processed_word[letter_index])\n",
    "                letter_node.parent = root # parent attribute used for bottom-up traversal\n",
    "                \n",
    "                root.children.append(letter_node)\n",
    "                root = letter_node\n",
    "                \n",
    "                # checking if the letter is the last one in the word\n",
    "                if letter_index == len(processed_word) - 1:\n",
    "                    letter_node.word_end = True\n",
    "                    letter_node.called_count += 1\n",
    "            \n",
    "            # deals with the case where the letter already exists\n",
    "            else:\n",
    "                for child in root.children:\n",
    "                    if child.data == processed_word[letter_index]:\n",
    "                        if letter_index == len(processed_word) - 1:\n",
    "                            child.called_count += 1\n",
    "                            child.word_end = True\n",
    "                        root = child\n",
    "                        break\n",
    "\n",
    "        \n",
    "    def lookup(self, word):\n",
    "        \"\"\"Determines whether a given word is present in the trie.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be looked-up in the trie.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if the word is present in trie; False otherwise.\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        Your trie should ignore whether a word is capitalized.\n",
    "        E.g. trie.insert('Prague') should lead to trie.lookup('prague') = True\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        root = self.root # starts the lookup at the root node\n",
    "        processed_word = word.lower() # converts the string to lower case\n",
    "\n",
    "        if word == \"\":\n",
    "            return False\n",
    "        \n",
    "        for letter_index in range(len(processed_word)):\n",
    "            if all([child.data != processed_word[letter_index] for child in root.children]):\n",
    "                    return False\n",
    "            else:\n",
    "                for child in root.children:\n",
    "                    if child.data == processed_word[letter_index]:\n",
    "                        root = child\n",
    "                        if letter_index == len(processed_word) - 1:\n",
    "                            if not child.word_end:\n",
    "                                  return False\n",
    "                        break # ends the for loop early if it finds a match\n",
    "        return True # only returns true if the for loop has moved through every letter in the word without an error\n",
    "\n",
    "    def alphabetical_list(self):\n",
    "        \"\"\"\n",
    "        Delivers the content of the trie in alphabetical order.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            List of strings, all words from the trie in alphabetical order.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        root = self.root\n",
    "\n",
    "        word_list = []  \n",
    "\n",
    "        def _alphabetical_list(letter_node, fragment):\n",
    "            \"\"\"\n",
    "            Inner function that executes and isolates the recursive part of alphabetical_list. \n",
    "            Performs tree traversal, keeping track of word fragments and recursively appending\n",
    "            fragments to word_list if they represent full words\n",
    "\n",
    "            Parameters\n",
    "            -----------\n",
    "            letter_node: Node\n",
    "                Starting node for the recursive function to execute from\n",
    "            fragment: str\n",
    "                string that represents the word fragment associated with the path up to that point\n",
    "\n",
    "            Output\n",
    "            ---------\n",
    "            None\n",
    "            \"\"\"\n",
    "            fragment += letter_node.data # recursively add nodes to the running variable fragment\n",
    "\n",
    "            if letter_node.word_end == True:\n",
    "                # Deals with leaf nodes\n",
    "                if letter_node.children == []:\n",
    "                    word_list.append(fragment)\n",
    "                # Deals with word-ends that aren't leaf nodes\n",
    "                else:\n",
    "                    word_list.append(fragment)\n",
    "                    for child in letter_node.children:\n",
    "                        _alphabetical_list(child, fragment)\n",
    "            # Deals with cases where the specified node is not a word_end\n",
    "            else:\n",
    "                for child in letter_node.children:\n",
    "                    _alphabetical_list(child, fragment) # recurse for all children\n",
    "\n",
    "        _alphabetical_list(root, \"\")\n",
    "        return sorted(word_list)\n",
    "\n",
    "    def k_most_common(self, k):\n",
    "        \"\"\"Finds k words inserted into the trie most often.\n",
    "\n",
    "        You will have to tweak some properties of your existing code,\n",
    "        so that it captures information about repeated insertion.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of most common words to be returned.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            List of tuples.\n",
    "\n",
    "            Each tuple entry consists of the word and its frequency.\n",
    "            The entries are sorted by frequency.\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        >>> print(trie.k_most_common(3))\n",
    "        [(‘the’, 154), (‘a’, 122), (‘i’, 122)]\n",
    "\n",
    "        I.e. the word ‘the’ has appeared 154 times in the inserted text.\n",
    "        The second and third most common words both appeared 122 times.\n",
    "        \"\"\"\n",
    "\n",
    "        if k < 1:\n",
    "            return \"Error: k must be greater than or equal to 1\"\n",
    "        end_node_list = []\n",
    "\n",
    "        root = self.root\n",
    "        \n",
    "        def _find_end_nodes(letter_node):\n",
    "            \"\"\"\n",
    "            Inner function that recurses through the tree and finds every node that is an ending\n",
    "            node\n",
    "\n",
    "            Parameters\n",
    "            -----------\n",
    "            letter_node: Node\n",
    "                Node from which the function starts finding all end nodes\n",
    "\n",
    "            Output\n",
    "            -----\n",
    "            None\n",
    "\n",
    "            \"\"\"\n",
    "            if letter_node.word_end == True:\n",
    "                # Deals with the case where the node is a leaf\n",
    "                if letter_node.children == []:\n",
    "                    end_node_list.append(letter_node)\n",
    "                # Deals withe the case where the node is an end_node but not a leaf\n",
    "                else:\n",
    "                    end_node_list.append(letter_node)\n",
    "                    for child in letter_node.children:\n",
    "                        _find_end_nodes(child)\n",
    "            # If not an end_node, recurse for all children of the node\n",
    "            else:\n",
    "                for child in letter_node.children:\n",
    "                    _find_end_nodes(child)\n",
    "        _find_end_nodes(root)\n",
    "\n",
    "        # Building a MaxHeap to order end nodes by their frequency\n",
    "        max_heap = MaxHeap(end_node_list)\n",
    "        for i in range((max_heap.heap_size//2), -1, -1):\n",
    "            max_heap.heapify(i)\n",
    "\n",
    "        def word_from_end_node(end_node):\n",
    "            \"\"\"\n",
    "            Constructs a word from a given end node by iterating upwards through the \n",
    "            tree until hitting the root\n",
    "\n",
    "            Parameters\n",
    "            ---------\n",
    "            end_node: Node\n",
    "                the end_node from which the algorithm constructs the word\n",
    "            \"\"\"\n",
    "            fragment = end_node.data\n",
    "            while end_node.data != \"\": # ends the iteration when it hits the root\n",
    "                end_node = end_node.parent\n",
    "                fragment += end_node.data\n",
    "            return fragment[::-1] # word is reversed because of upwards traversal, so this reverses that\n",
    "\n",
    "        k_words_list = []\n",
    "\n",
    "        for i in range(k): # return the number of most common words specified by the user\n",
    "            if max_heap.heap_size > 0: # doesn't return anything if there are no more words left\n",
    "                end_node = max_heap.heappop()\n",
    "                word = word_from_end_node(end_node)\n",
    "                k_words_list.append((word, end_node.called_count))\n",
    "\n",
    "        k_words_list.sort(key = lambda x:(-x[1], x[0])) # sort first according to count, and second alphabetically\n",
    "        return k_words_list\n",
    "\n",
    "    def autocomplete(self, prefix):\n",
    "        \"\"\"Finds the most common word with the given prefix.\n",
    "\n",
    "        You might want to reuse some functionality or ideas from Q4.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        prefix : str\n",
    "            The word part to be “autocompleted”.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        str\n",
    "            The complete, most common word with the given prefix.\n",
    "            \n",
    "        Notes\n",
    "        ----------\n",
    "        The return value is equal to prefix if there is no valid word in the trie.\n",
    "        The return value is also equal to prefix if prefix is the most common word.\n",
    "        \"\"\"\n",
    "        \n",
    "        # search for the node in the tree to start from\n",
    "        root = self.root\n",
    "        end_node_list = []\n",
    "        \n",
    "        if prefix == \"\":\n",
    "            return \"\"\n",
    "        \n",
    "        if type(prefix) != str:\n",
    "            return \"Error: prefix must be of type string\"\n",
    "        \n",
    "        def find_starting_node(root, prefix):\n",
    "            \"\"\"\n",
    "            Inner function that finds the node to start from, which is the last letter of the prefix\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            prefix: string\n",
    "                prefix of the word to autocomplete\n",
    "        \n",
    "            Output\n",
    "            ------\n",
    "            starting_node: Node\n",
    "                returns the starting node \n",
    "            \"\"\"\n",
    "            for letter in prefix:\n",
    "                # Determines if the tree contains the prefix and returns it if not\n",
    "                if all([child.data != letter for child in root.children]):\n",
    "                    return prefix\n",
    "                for child in root.children:\n",
    "                    if child.data == letter:\n",
    "                        root = child\n",
    "            return root\n",
    "        \n",
    "        def find_end_nodes(letter_node):\n",
    "            \"\"\"\n",
    "            Finds all end nodes in the sub-tree that has the last letter of the prefix as \n",
    "            the starting node\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            letter_node: Node\n",
    "                starting node from which the algorithm finds all end nodes in the tree\n",
    "            \n",
    "            Output\n",
    "            ------\n",
    "            None (appends end nodes to the word list)\n",
    "            \n",
    "            \"\"\"\n",
    "            if letter_node.word_end == True:\n",
    "                # Deals with leaf nodes\n",
    "                if letter_node.children == []:\n",
    "                    end_node_list.append(letter_node)\n",
    "                # Deals recursively with word ends that aren't leaf nodes\n",
    "                else:\n",
    "                    end_node_list.append(letter_node)\n",
    "                    for child in letter_node.children:\n",
    "                        find_end_nodes(child)\n",
    "            # Recurses down the tree to find more end nodes\n",
    "            else:\n",
    "                for child in letter_node.children:\n",
    "                    find_end_nodes(child)\n",
    "        \n",
    "        def word_from_end_node(end_node):\n",
    "            \"\"\"\n",
    "            Inner function that constructs a word from the given end node by iterating upwards\n",
    "            through the tree\n",
    "            \n",
    "            Parameters\n",
    "            ---------\n",
    "            end_node: Node\n",
    "                Final node in the word\n",
    "            \n",
    "            \"\"\"\n",
    "            fragment = end_node.data\n",
    "            while end_node.data != \"\": # breaks the iteration once it reaches the root\n",
    "                end_node = end_node.parent\n",
    "                fragment += end_node.data\n",
    "            return fragment[::-1] # reverses the word, because upwards traversal produces a mirrored word\n",
    "                    \n",
    "        starting_node = find_starting_node(root, prefix)\n",
    "        \n",
    "        if starting_node == prefix: # returns the prefix if it's not in the tree\n",
    "            return prefix\n",
    "        else:\n",
    "            find_end_nodes(starting_node)\n",
    "\n",
    "        # builds a max heap from the end_nodes previously identified\n",
    "        max_heap = MaxHeap(end_node_list)\n",
    "        for i in range((max_heap.heap_size//2), -1, -1):\n",
    "            max_heap.heapify(i)\n",
    "        \n",
    "        \n",
    "        most_common_end_node = max_heap.heappop()\n",
    "        # constructs the word from the most common end node\n",
    "        most_common_word = word_from_end_node(most_common_end_node) \n",
    "        \n",
    "        return most_common_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4d7b237d8fef1472153a888da73a5fa5",
     "grade": true,
     "grade_id": "cell-e65110651f531630",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# depending on your choice of approach, uncomment one of the lines below\n",
    "# The Complete Works of William Shakespeare is a LARGE book, \n",
    "# so the code might take a while to run\n",
    "\n",
    "from requests import get\n",
    "bad_chars = [';', ',', '.', '?', '!', '1', '2', '3', '4',\n",
    "             '5', '6', '7', '8', '9', '0', '_', '[', ']']\n",
    "\n",
    "SH_full = get('http://bit.ly/CS110-Shakespeare').text\n",
    "SH_just_text = ''.join(c for c in SH_full if c not in bad_chars)\n",
    "SH_without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in SH_just_text)\n",
    "SH_just_words = [word for word in SH_without_newlines.split(\" \") if word != \"\"]\n",
    "\n",
    "SH_trie = Trie(SH_just_words)\n",
    "\n",
    "assert SH_trie.autocomplete('hist') == 'history'\n",
    "assert SH_trie.autocomplete('en') == 'enter'\n",
    "assert SH_trie.autocomplete('cae') == 'caesar'\n",
    "assert SH_trie.autocomplete('gen') == 'gentleman'\n",
    "assert SH_trie.autocomplete('pen') == 'pen'\n",
    "assert SH_trie.autocomplete('tho') == 'thou'\n",
    "assert SH_trie.autocomplete('pent') == 'pentapolis'\n",
    "assert SH_trie.autocomplete('petr') == 'petruchio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4d7b237d8fef1472153a888da73a5fa5",
     "grade": true,
     "grade_id": "cell-e65110651f531630",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wordbank = \"Ai! laurië lantar lassi súrinen, yéni unótimë ve rámar aldaron! Yéni ve lintë yuldar avánier mi oromardi lisse-miruvóreva Andúnë pella, Vardo tellumar nu luini yassen tintilar i eleni ómaryo airetári-lírinen. Sí man i yulma nin enquantuva? An sí Tintallë Varda Oiolossëo ve fanyar máryat Elentári ortanë, ar ilyë tier undulávë lumbulë; ar sindanóriello caita mornië i falmalinnar imbë met, ar hísië untúpa Calaciryo míri oialë. Sí vanwa ná, Rómello vanwa, Valimar! Namárië! Nai hiruvalyë Valimar. Nai elyë hiruva. Namárië!\".replace(\"!\", \"\").replace(\"?\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\";\", \"\").split()\n",
    "\n",
    "trie = Trie(wordbank)\n",
    "assert trie.autocomplete('a') == 'ar'\n",
    "assert trie.autocomplete('fail test') == \"fail test\"\n",
    "assert trie.autocomplete(\"\") == \"\"\n",
    "assert trie.autocomplete(1) == \"Error: prefix must be of type string\"\n",
    "assert trie.autocomplete('ai') == 'ai'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0900cfbb08f4049be7cb085ac1aa6e42",
     "grade": true,
     "grade_id": "cell-f1fb8e081b7fcaf3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "# Test Justifications\n",
    "For my test, I chose to focus on small-scale problems and edge cases, because the Shakespeare tests indicate that the algorithm likely has no problems parsing large English-character texts.\n",
    "\n",
    "First, I simply tested the two conditions of the algorithm: filling in the rest of the word and returning the prefix if no word is found. Then, I moved onto edge cases: I built in special logic to handle the input \"\", because technically it's the prefix to every word in the tree, leading the algorithm to return the most common word (determined alphabetically in the case of a tie). This is unwanted behaviour: any auto-completion engine shouldn't make suggestions before the user has typed anything. \n",
    "\n",
    "Then I tested two possible error conditions: non-string inputs and inputing the entire word as the prefix. The former I handled through type-checking logic in the algorithm, and the latter naturally returns the specified word.\n",
    "\n",
    "These tests are appropriate because they test edge cases for the algorithm that aren't necessarily handled by any straightforward implementation of the code. As a supplement to the Shakespeare tests, they ensure we're testing unique inputs as well as large datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Analysis\n",
    "ake sure to include a minimum **100 word-summary critically evaluating** your autocomplete engine. How does it really work? Your critical reflection needs to specifically evaluate the role of the different data structures used by their algorithm and what is the overall complexity that the algorithm offers. Can we do better? If so, how and by how much\n",
    "\n",
    "\n",
    "The auto-completion algorithm works in four stages: \n",
    "1. **find_starting_node:** First, it searches through the tree to find the sub-tree associated with the prefix argument. If the prefix doesn't exist, it simply returns the prefix itself and stops running. Otherwise, it returns the node associated with the last letter of the prefix.\n",
    "2. **find_end_nodes:** Second, it finds all nodes that are word endings for words that start with the prefix. It does so by treating the last letter of the prefix as the root node, and recursively moving down the tree from that point, appending each ``word_end`` node to a list.\n",
    "3. **building maxheap:** Third, it constructs a max heap using all of the end-nodes that it's identified. After ensuriang the max-heap property, it pops the root node, which is the end node associated with the most common word that starts with the prefix.\n",
    "4. **word_from_end_node:** Fourth, it constructs a word from the most common end node by moving back up through the tree from the end node until the root, keeping track of the word fragment that's built up as it does so.\n",
    "\n",
    "\n",
    "### Time Complexity\n",
    "The total time complexity of the algorithm is the sum of the time complexities of its steps:\n",
    "\n",
    "**find_starting_node**\n",
    "To find the starting node, the algorithm has to iterate once for each letter in the prefix (designated ``k``). As discussed above, asymptotically we can treat iteration through the children of a node as taking constant time ``O(1)``, because for an English text, the number of children is likely to never rise above 20-30 (and that will only occur in extreme cases). This happens twice, because for each node the code iterates through the children twice.\n",
    "This means the overal time complexity is:\n",
    "$$O(k)*(O(1)+O(1))=O(k)*2O(1)=O(k)$$\n",
    "\n",
    "**find_end_nodes**\n",
    "Finding the end-nodes is likely to be the largest contributor to time complexity in the algorithm, because it depends on the number of nodes in the tree, rather than the length of the input word. It's called exactly once for each node in the tree, and for each one only performs constant time operations (appending to a list, comparison). This means it has time complexity ``Theta(n)``, where ``n`` is the number of nodes in the sub-tree after the prefix.\n",
    "\n",
    "**building and popping maxheap**\n",
    "To construct the max-heap, we call ``heapify()`` ``h//2`` times, where ``h`` is the number of end-nodes in the sub-tree that has the prefix as its root. Heapify takes time proportional to the height of the heap ``O(log h)`` and is called ``h//2`` times. This means the overall time complexity is ``O(h log h)``.\n",
    "\n",
    "Popping the max-heap also requires a call to heapify to maintain the heap invariant, which takes ``O(log h)`` time.\n",
    "\n",
    "The max-heap is an excellent data structure to use here, because it has excellent time complexities for finding and removing the maximum.\n",
    "\n",
    "**word_from_end_node**\n",
    "This subroutine traces a path from an end-node to the root. Since my trie tree is not binary, its height does not have a specific relationship to its number of nodes. For now, we'll designate it ``q``. Since this operation is only performed once, it has time compexity ``O(q)``.\n",
    "\n",
    "#### Summary Time Complexity\n",
    "The overall time complexity is the summation of all the time complexities of the sub-routines:\n",
    "$$=O(k)+Theta(n)+O(h log h)+O(log h)+O(q)$$\n",
    "- k is the length of the word prefix\n",
    "- n is the number of nodes in the subtree that has the prefix as its root\n",
    "-  h is the number of end-nodes in the sub-tree that has the prefix as its root \n",
    "- q is the height of the tree from the highest value end-node (not necessarily a leaf)\n",
    "\n",
    "We can use intuition to determine which terms are asymptotically most important. First, for any reasonable trie tree, the ``k`` term is likely to be irreleevant, because most words in English are quite short, and prefixes even more so. We also know that the number of nodes in the subtree that has the prefix as its root should grow much faster than ``h`` and ``q``, both of which are related to ``n`` but are much smaller.\n",
    "\n",
    "Therefore, the simplest time complexity that we can arrive at is ``O(n)``. Because of the way that language is structured, the prefix cuts off a massive number of possibilities. This means we can't generalise and say that it takes time proportional to the number of nodes in the tree as a whole.\n",
    "\n",
    "In short, the algorithm should asymptotically take linear time for the number of nodes in the sub-tree, but with extremely high coefficients that represent all of the other terms that we're disregarding.\n",
    "\n",
    "\n",
    "### Time Complexity: Can we do better?\n",
    "These alternatives certainly provide quantitative improvements, but they cannot change the overall ``O(n)`` time complexity -- they simply improve hidden coefficients.\n",
    "\n",
    "To improve the overall time complexity, we would need to adjust **find_end_nodes** so that it took less than linear time. This is impossible with my existing trie tree, because the data structure provides no information about where these end_nodes are that we could use to decrease the amount of work we have to perform (they don't even have to be leaves). This means you always have to check every node -- it will always have a linear time complexity.\n",
    "\n",
    "### Alternatives\n",
    "There are some optimisations that you could make to the process above without changing the data structure or approach drastically:\n",
    "- When building the word from the end-node, stop as soon as you hit the end of the prefix and simply append the word fragment to the prefix. I didn't implement this because the prefix is likely never going to be long enough to have any impact on the time requirement, and because I was worried about possible edge cases such as the word having the prefix in it twice. This would improve the time complexity by ``Theta(k)``, where ``k`` is the length of the prefix.\n",
    "\n",
    "\n",
    "- In the ``find_starting_node`` subroutine, combine the process of checking whether any node is the child with the process of identifying which one is the child. I didn't implement this because it would have prevented me from using the optimised `all` function and probably forced me to use a temporary list for storing Boolean values. This would decrease the coefficient of the ``O(h)`` term for the sub-routine, where ``h`` is the average number of children per node.\n",
    "\n",
    "\n",
    "## Space Complexity\n",
    "\n",
    "My implementation only creates a single temporary data structure used ot hold information. It appends all relevant end-nodes for the prefix sub-tree to a list, which then becomes a heap. This has space complexity ``Theta(h)``, where ``h`` is the number of end-nodes in the subtree.\n",
    "\n",
    "There's one way of improving this space complexity, at the cost of additional time complexity. Instead of maintaining a list of elements, you initialise and mutate running variables that capture the best end-node and the number of times it was called. You update these variables whenever you come to a better solution, and then move upwards to the root from the node, constructing the associated word as you do so. This is an extremely promising approach -- it doesn't require the use of a heap data structure, simplifying the code.\n",
    "\n",
    "This optimisation becomes far more important for large datasets (e.g. if we were implementing this for a large company), where there might be hundreds of thousands of unique words.\n",
    "\n",
    "I've already made over small changes to my code that optimise the space complexity. For example, only end_nodes store the frequency with which the word has been inserted into the tree, because doing so for all nodes would be redundant for our purposes.\n",
    "\n",
    "I've also made it such that nodes only store letters, rather than the word fragments associated with the tree up to that point. Path traversal from a node to the root using a ``parent`` attribute is then used to construct each word.\n",
    "\n",
    "\n",
    "## Code Readability\n",
    "The solution that I implemented was partially chosen to optimise code readability, and to make the algorithm as easy to debug as possible. By separating responsibilities into inner functions, I could test each one's output to ensure it was performing as expected, and analyse time complexity as a summation of the time complexities of the inner functions. By using a list instead of parameter variables, I could also test to make sure that the recursion was working properly and was appending appropriate end nodes.\n",
    "\n",
    "### Failure Modes/Context\n",
    "At the moment, the main failure modes of the tree occur with generalisation to non-english alphabets. This occurs for two reasons: first, many alphabets (e.g. Japanese, Chinese) don't use spaces to designate words. This would be a complicated implementation that would need some knowledge of the language grammar to work properly. For example, Japanese uses special characters called particles to represent grammar. The autocompletion would have to distinguish between words and particles to work effectively.\n",
    "\n",
    "The second reason is that many text inputs use characters that can't be parsed by Python. Fixing this requires standardising inputs through pre-processing. For example, the tree could use binary or ASCII to represent characters, which are more format agnostic.\n",
    "\n",
    "A failure mode also occurs when users are using vernacular that differs significantly from the corpus used to construct the tree. For example, very rarely should a tree recommend the word 'thou' for a modern English texter. The tree also has to be able to auto-complete words that modern speakers would use, such as 'computer', 'internet', etc. Training auto-completion on Shakespeare might not be the best approach for this :).\n",
    "\n",
    "The significance of these failure modes depends on the context. For word analysis of a corpus (e.g. if empirically studying something like Zipf's law), this algorithm works extremely well. For modern auto-completion that works well across many vernaculars, contexts and languages, it's extremely simplistic.\n",
    "\n",
    "### Possible Extensions\n",
    "\n",
    "#### Linking Suffixes\n",
    "One space/time complexity optimisation is linking common suffixes of separate tree branches. This decreases the total number of nodes in the tree, making traversal faster and taking up less space by decreasing redundency and encoding relationships more efficiently.\n",
    "\n",
    "#### Better Auto-Completion\n",
    "There are many other ways of determining which word should be auto-completed that are more comprehensive than this frequentist approach. In particular, convolutional neural networks allow for the inclusion of the context of the sentence, which in many cases will be more important than word frequency.\n",
    "\n",
    "# Summary\n",
    "In short, the algorithm performs relatively well in terms of time and space complexity. It uses data structures (heaps, lists and the trie tree) to balance intuitive implementation and efficient execution, and its time complexity has the same asymptotic functional form as that of an optimally implemented trie tree. There are definitely  improvements that can be made to its complexity, ranging from decreasing the number of total nodes by linking branches to replacing the heap/list structure with parameter variables that update for each end node. This latter improvement in particular promises improvements in time and space complexity: the former remains asymptotically the same, and the latter decreases to ``O(1)``, because you're only ever storing one node. Unless dealing with the constraint of a massive corpus of words, however, the existing solution has appropriate complexities and has the advantage of being understandable. It also has the advantage that by popping multiple words from the tree, you can recommend several most common words for auto-completion, which is impossible with the parameter variable approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: HC Applications\n",
    "\n",
    "- **#breakitdown**: to construct the auto-completion algorithm, I carefully considered the requisite steps and used inner functions to isolate and execute each aspect of the algorithm. After implementing this function, I analysed in detail the effectiveness of both my overall solution and its components, drawing on its time and space complexity, the contexts in which it will be used, and its code readability. I critique my problem decomposition, and provide suggestions for alternatives that could improve the metrics that I'd chosen to optimise for (complexity, readability, usefulness). I highlight the advantages and disadvantages of these alternatives, and describe how they can be implemented through an alternative decomposition (using parameter variables rather than a heap).\n",
    "\n",
    "- **#algorithms**: throughout this assignment, I identified appropriate algorithmic strategies, justifying my implementations through the lenses of readability, applicability, and time complexity. I interpret and critique my algorithmic decisions, drawing on principles of effective programming such as the Single Responsibility Principle. I also provide thorough explanations of my code, both through docstrings/comments and written explanations.\n",
    "\n",
    "- **networks**: throughout this assignment, I conduct a detailed analysis of the structure of a trie tree (a specific case of a directed network). Leveraging this analysis, I design algorithms that leverage the particular effects of the network, such as the fact that the complexity of resulting algorithms is often based on the length of the input word, rather than the height of the tree itself. I contrast two network-based solutions to the problem of dictionary mapping (BSTs and trie trees), highlighting how the structure of the latter has properties that make it preferable compared to the former for my specific use case. I also justify the attributes, methods and relationships of nodes within the network, highlighting how these properties allow me to leverage the structure to improve my algorithms (e.g. efficient traversal across the network in both directions)"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/5f6ef786fbd71f033902b72807f18915"
  },
  "celltoolbar": "Edit Metadata",
  "gist": {
   "data": {
    "description": "CS110_A3_Tries.ipynb",
    "public": false
   },
   "id": "5f6ef786fbd71f033902b72807f18915"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
